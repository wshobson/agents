{
  "id": "systems_programming_go_concurrency_patterns",
  "name": "go-concurrency-patterns",
  "source": "systems-programming",
  "originalPath": "plugins/systems-programming/skills/go-concurrency-patterns/SKILL.md",
  "activationCriteria": "Master Go concurrency with goroutines, channels, sync primitives, and context. Use when building concurrent Go applications, implementing worker pools, or debugging race conditions.",
  "tier1_metadata": "go-concurrency-patterns: Master Go concurrency with goroutines, channels, sync primitives, and context. Use when building con",
  "tier2_instructions": "# Go Concurrency Patterns\n\nProduction patterns for Go concurrency including goroutines, channels, synchronization primitives, and context management.\n\n## When to Use This Skill\n\n- Building concurrent Go applications\n- Implementing worker pools and pipelines\n- Managing goroutine lifecycles\n- Using channels for communication\n- Debugging race conditions\n- Implementing graceful shutdown\n\n## Core Concepts\n\n### 1. Go Concurrency Primitives\n\n| Primitive | Purpose |\n|-----------|---------|\n| `goroutine` | Lightweight concurrent execution |\n| `channel` | Communication between goroutines |\n| `select` | Multiplex channel operations |\n| `sync.Mutex` | Mutual exclusion |\n| `sync.WaitGroup` | Wait for goroutines to complete |\n| `context.Context` | Cancellation and deadlines |\n\n### 2. Go Concurrency Mantra\n\n```\nDon't communicate by sharing memory;\nshare memory by communicating.\n```\n\n## Quick Start\n\n```go\npackage main\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"sync\"\n    \"time\"\n)\n\nfunc main() {\n    ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)\n    defer cancel()\n\n    results := make(chan string, 10)\n    var wg sync.WaitGroup\n\n    // Spawn workers\n    for i := 0; i < 3; i++ {\n        wg.Add(1)\n        go worker(ctx, i, results, &wg)\n    }\n\n    // Close results when done\n    go func() {\n        wg.Wait()\n        close(results)\n    }()\n\n    // Collect results\n    for result := range results {\n        fmt.Println(result)\n    }\n}\n\nfunc worker(ctx context.Context, id int, results chan<- string, wg *sync.WaitGroup) {\n    defer wg.Done()\n\n    select {\n    case <-ctx.Done():\n        return\n    case results <- fmt.Sprintf(\"Worker %d done\", id):\n    }\n}\n```\n\n## Patterns\n\n### Pattern 1: Worker Pool\n\n```go\npackage main\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"sync\"\n)\n\ntype Job struct {\n    ID   int\n    Data string\n}\n\ntype Result struct {\n    JobID int\n    Output string\n    Err   error\n}\n\nfunc WorkerPool(ctx context.Context, numWorkers int, jobs <-chan Job) <-chan Result {\n   ",
  "tier3_resources": " results := make(chan Result, len(jobs))\n\n    var wg sync.WaitGroup\n    for i := 0; i < numWorkers; i++ {\n        wg.Add(1)\n        go func(workerID int) {\n            defer wg.Done()\n            for job := range jobs {\n                select {\n                case <-ctx.Done():\n                    return\n                default:\n                    result := processJob(job)\n                    results <- result\n                }\n            }\n        }(i)\n    }\n\n    go func() {\n        wg.Wait()\n        close(results)\n    }()\n\n    return results\n}\n\nfunc processJob(job Job) Result {\n    // Simulate work\n    return Result{\n        JobID:  job.ID,\n        Output: fmt.Sprintf(\"Processed: %s\", job.Data),\n    }\n}\n\n// Usage\nfunc main() {\n    ctx, cancel := context.WithCancel(context.Background())\n    defer cancel()\n\n    jobs := make(chan Job, 100)\n\n    // Send jobs\n    go func() {\n        for i := 0; i < 50; i++ {\n            jobs <- Job{ID: i, Data: fmt.Sprintf(\"job-%d\", i)}\n        }\n        close(jobs)\n    }()\n\n    // Process with 5 workers\n    results := WorkerPool(ctx, 5, jobs)\n\n    for result := range results {\n        fmt.Printf(\"Result: %+v\\n\", result)\n    }\n}\n```\n\n### Pattern 2: Fan-Out/Fan-In Pipeline\n\n```go\npackage main\n\nimport (\n    \"context\"\n    \"sync\"\n)\n\n// Stage 1: Generate numbers\nfunc generate(ctx context.Context, nums ...int) <-chan int {\n    out := make(chan int)\n    go func() {\n        defer close(out)\n        for _, n := range nums {\n            select {\n            case <-ctx.Done():\n                return\n            case out <- n:\n            }\n        }\n    }()\n    return out\n}\n\n// Stage 2: Square numbers (can run multiple instances)\nfunc square(ctx context.Context, in <-chan int) <-chan int {\n    out := make(chan int)\n    go func() {\n        defer close(out)\n        for n := range in {\n            select {\n            case <-ctx.Done():\n                return\n            case out <- n * n:\n            }\n        }\n    }()\n    return out\n}\n\n// Fan-in: Merge multiple channels into one\nfunc merge(ctx context.Context, cs ...<-chan int) <-chan int {\n    var wg sync.WaitGroup\n    out := make(chan int)\n\n    // Start output goroutine for each input channel\n    output := func(c <-chan int) {\n        defer wg.Done()\n        for n := range c {\n            select {\n            case <-ctx.Done():\n                return\n            case out <- n:\n            }\n        }\n    }\n\n    wg.Add(len(cs))\n    for _, c := range cs {\n        go output(c)\n    }\n\n    // Close out after all inputs are done\n    go func() {\n        wg.Wait()\n        close(out)\n    }()\n\n    return out\n}\n\nfunc main() {\n    ctx, cancel := context.WithCancel(context.Background())\n    defer cancel()\n\n    // Generate input\n    in := generate(ctx, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10)\n\n    // Fan out to multiple squarers\n    c1 := square(ctx, in)\n    c2 := square(ctx, in)\n    c3 := square(ctx, in)\n\n    // Fan in results\n    for result := range merge(ctx, c1, c2, c3) {\n        fmt.Println",
  "tokenEstimate": {
    "tier1": 19.5,
    "tier2": 353.6,
    "tier3": 1799.2
  },
  "fullDefinition": "---\nname: go-concurrency-patterns\ndescription: Master Go concurrency with goroutines, channels, sync primitives, and context. Use when building concurrent Go applications, implementing worker pools, or debugging race conditions.\n---\n\n# Go Concurrency Patterns\n\nProduction patterns for Go concurrency including goroutines, channels, synchronization primitives, and context management.\n\n## When to Use This Skill\n\n- Building concurrent Go applications\n- Implementing worker pools and pipelines\n- Managing goroutine lifecycles\n- Using channels for communication\n- Debugging race conditions\n- Implementing graceful shutdown\n\n## Core Concepts\n\n### 1. Go Concurrency Primitives\n\n| Primitive | Purpose |\n|-----------|---------|\n| `goroutine` | Lightweight concurrent execution |\n| `channel` | Communication between goroutines |\n| `select` | Multiplex channel operations |\n| `sync.Mutex` | Mutual exclusion |\n| `sync.WaitGroup` | Wait for goroutines to complete |\n| `context.Context` | Cancellation and deadlines |\n\n### 2. Go Concurrency Mantra\n\n```\nDon't communicate by sharing memory;\nshare memory by communicating.\n```\n\n## Quick Start\n\n```go\npackage main\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"sync\"\n    \"time\"\n)\n\nfunc main() {\n    ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)\n    defer cancel()\n\n    results := make(chan string, 10)\n    var wg sync.WaitGroup\n\n    // Spawn workers\n    for i := 0; i < 3; i++ {\n        wg.Add(1)\n        go worker(ctx, i, results, &wg)\n    }\n\n    // Close results when done\n    go func() {\n        wg.Wait()\n        close(results)\n    }()\n\n    // Collect results\n    for result := range results {\n        fmt.Println(result)\n    }\n}\n\nfunc worker(ctx context.Context, id int, results chan<- string, wg *sync.WaitGroup) {\n    defer wg.Done()\n\n    select {\n    case <-ctx.Done():\n        return\n    case results <- fmt.Sprintf(\"Worker %d done\", id):\n    }\n}\n```\n\n## Patterns\n\n### Pattern 1: Worker Pool\n\n```go\npackage main\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"sync\"\n)\n\ntype Job struct {\n    ID   int\n    Data string\n}\n\ntype Result struct {\n    JobID int\n    Output string\n    Err   error\n}\n\nfunc WorkerPool(ctx context.Context, numWorkers int, jobs <-chan Job) <-chan Result {\n    results := make(chan Result, len(jobs))\n\n    var wg sync.WaitGroup\n    for i := 0; i < numWorkers; i++ {\n        wg.Add(1)\n        go func(workerID int) {\n            defer wg.Done()\n            for job := range jobs {\n                select {\n                case <-ctx.Done():\n                    return\n                default:\n                    result := processJob(job)\n                    results <- result\n                }\n            }\n        }(i)\n    }\n\n    go func() {\n        wg.Wait()\n        close(results)\n    }()\n\n    return results\n}\n\nfunc processJob(job Job) Result {\n    // Simulate work\n    return Result{\n        JobID:  job.ID,\n        Output: fmt.Sprintf(\"Processed: %s\", job.Data),\n    }\n}\n\n// Usage\nfunc main() {\n    ctx, cancel := context.WithCancel(context.Background())\n    defer cancel()\n\n    jobs := make(chan Job, 100)\n\n    // Send jobs\n    go func() {\n        for i := 0; i < 50; i++ {\n            jobs <- Job{ID: i, Data: fmt.Sprintf(\"job-%d\", i)}\n        }\n        close(jobs)\n    }()\n\n    // Process with 5 workers\n    results := WorkerPool(ctx, 5, jobs)\n\n    for result := range results {\n        fmt.Printf(\"Result: %+v\\n\", result)\n    }\n}\n```\n\n### Pattern 2: Fan-Out/Fan-In Pipeline\n\n```go\npackage main\n\nimport (\n    \"context\"\n    \"sync\"\n)\n\n// Stage 1: Generate numbers\nfunc generate(ctx context.Context, nums ...int) <-chan int {\n    out := make(chan int)\n    go func() {\n        defer close(out)\n        for _, n := range nums {\n            select {\n            case <-ctx.Done():\n                return\n            case out <- n:\n            }\n        }\n    }()\n    return out\n}\n\n// Stage 2: Square numbers (can run multiple instances)\nfunc square(ctx context.Context, in <-chan int) <-chan int {\n    out := make(chan int)\n    go func() {\n        defer close(out)\n        for n := range in {\n            select {\n            case <-ctx.Done():\n                return\n            case out <- n * n:\n            }\n        }\n    }()\n    return out\n}\n\n// Fan-in: Merge multiple channels into one\nfunc merge(ctx context.Context, cs ...<-chan int) <-chan int {\n    var wg sync.WaitGroup\n    out := make(chan int)\n\n    // Start output goroutine for each input channel\n    output := func(c <-chan int) {\n        defer wg.Done()\n        for n := range c {\n            select {\n            case <-ctx.Done():\n                return\n            case out <- n:\n            }\n        }\n    }\n\n    wg.Add(len(cs))\n    for _, c := range cs {\n        go output(c)\n    }\n\n    // Close out after all inputs are done\n    go func() {\n        wg.Wait()\n        close(out)\n    }()\n\n    return out\n}\n\nfunc main() {\n    ctx, cancel := context.WithCancel(context.Background())\n    defer cancel()\n\n    // Generate input\n    in := generate(ctx, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10)\n\n    // Fan out to multiple squarers\n    c1 := square(ctx, in)\n    c2 := square(ctx, in)\n    c3 := square(ctx, in)\n\n    // Fan in results\n    for result := range merge(ctx, c1, c2, c3) {\n        fmt.Println(result)\n    }\n}\n```\n\n### Pattern 3: Bounded Concurrency with Semaphore\n\n```go\npackage main\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"golang.org/x/sync/semaphore\"\n    \"sync\"\n)\n\ntype RateLimitedWorker struct {\n    sem *semaphore.Weighted\n}\n\nfunc NewRateLimitedWorker(maxConcurrent int64) *RateLimitedWorker {\n    return &RateLimitedWorker{\n        sem: semaphore.NewWeighted(maxConcurrent),\n    }\n}\n\nfunc (w *RateLimitedWorker) Do(ctx context.Context, tasks []func() error) []error {\n    var (\n        wg     sync.WaitGroup\n        mu     sync.Mutex\n        errors []error\n    )\n\n    for _, task := range tasks {\n        // Acquire semaphore (blocks if at limit)\n        if err := w.sem.Acquire(ctx, 1); err != nil {\n            return []error{err}\n        }\n\n        wg.Add(1)\n        go func(t func() error) {\n            defer wg.Done()\n            defer w.sem.Release(1)\n\n            if err := t(); err != nil {\n                mu.Lock()\n                errors = append(errors, err)\n                mu.Unlock()\n            }\n        }(task)\n    }\n\n    wg.Wait()\n    return errors\n}\n\n// Alternative: Channel-based semaphore\ntype Semaphore chan struct{}\n\nfunc NewSemaphore(n int) Semaphore {\n    return make(chan struct{}, n)\n}\n\nfunc (s Semaphore) Acquire() {\n    s <- struct{}{}\n}\n\nfunc (s Semaphore) Release() {\n    <-s\n}\n```\n\n### Pattern 4: Graceful Shutdown\n\n```go\npackage main\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"os\"\n    \"os/signal\"\n    \"sync\"\n    \"syscall\"\n    \"time\"\n)\n\ntype Server struct {\n    shutdown chan struct{}\n    wg       sync.WaitGroup\n}\n\nfunc NewServer() *Server {\n    return &Server{\n        shutdown: make(chan struct{}),\n    }\n}\n\nfunc (s *Server) Start(ctx context.Context) {\n    // Start workers\n    for i := 0; i < 5; i++ {\n        s.wg.Add(1)\n        go s.worker(ctx, i)\n    }\n}\n\nfunc (s *Server) worker(ctx context.Context, id int) {\n    defer s.wg.Done()\n    defer fmt.Printf(\"Worker %d stopped\\n\", id)\n\n    ticker := time.NewTicker(time.Second)\n    defer ticker.Stop()\n\n    for {\n        select {\n        case <-ctx.Done():\n            // Cleanup\n            fmt.Printf(\"Worker %d cleaning up...\\n\", id)\n            time.Sleep(500 * time.Millisecond) // Simulated cleanup\n            return\n        case <-ticker.C:\n            fmt.Printf(\"Worker %d working...\\n\", id)\n        }\n    }\n}\n\nfunc (s *Server) Shutdown(timeout time.Duration) {\n    // Signal shutdown\n    close(s.shutdown)\n\n    // Wait with timeout\n    done := make(chan struct{})\n    go func() {\n        s.wg.Wait()\n        close(done)\n    }()\n\n    select {\n    case <-done:\n        fmt.Println(\"Clean shutdown completed\")\n    case <-time.After(timeout):\n        fmt.Println(\"Shutdown timed out, forcing exit\")\n    }\n}\n\nfunc main() {\n    // Setup signal handling\n    ctx, cancel := context.WithCancel(context.Background())\n\n    sigCh := make(chan os.Signal, 1)\n    signal.Notify(sigCh, syscall.SIGINT, syscall.SIGTERM)\n\n    server := NewServer()\n    server.Start(ctx)\n\n    // Wait for signal\n    sig := <-sigCh\n    fmt.Printf(\"\\nReceived signal: %v\\n\", sig)\n\n    // Cancel context to stop workers\n    cancel()\n\n    // Wait for graceful shutdown\n    server.Shutdown(5 * time.Second)\n}\n```\n\n### Pattern 5: Error Group with Cancellation\n\n```go\npackage main\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"golang.org/x/sync/errgroup\"\n    \"net/http\"\n)\n\nfunc fetchAllURLs(ctx context.Context, urls []string) ([]string, error) {\n    g, ctx := errgroup.WithContext(ctx)\n\n    results := make([]string, len(urls))\n\n    for i, url := range urls {\n        i, url := i, url // Capture loop variables\n\n        g.Go(func() error {\n            req, err := http.NewRequestWithContext(ctx, \"GET\", url, nil)\n            if err != nil {\n                return fmt.Errorf(\"creating request for %s: %w\", url, err)\n            }\n\n            resp, err := http.DefaultClient.Do(req)\n            if err != nil {\n                return fmt.Errorf(\"fetching %s: %w\", url, err)\n            }\n            defer resp.Body.Close()\n\n            results[i] = fmt.Sprintf(\"%s: %d\", url, resp.StatusCode)\n            return nil\n        })\n    }\n\n    // Wait for all goroutines to complete or one to fail\n    if err := g.Wait(); err != nil {\n        return nil, err // First error cancels all others\n    }\n\n    return results, nil\n}\n\n// With concurrency limit\nfunc fetchWithLimit(ctx context.Context, urls []string, limit int) ([]string, error) {\n    g, ctx := errgroup.WithContext(ctx)\n    g.SetLimit(limit) // Max concurrent goroutines\n\n    results := make([]string, len(urls))\n    var mu sync.Mutex\n\n    for i, url := range urls {\n        i, url := i, url\n\n        g.Go(func() error {\n            result, err := fetchURL(ctx, url)\n            if err != nil {\n                return err\n            }\n\n            mu.Lock()\n            results[i] = result\n            mu.Unlock()\n            return nil\n        })\n    }\n\n    if err := g.Wait(); err != nil {\n        return nil, err\n    }\n\n    return results, nil\n}\n```\n\n### Pattern 6: Concurrent Map with sync.Map\n\n```go\npackage main\n\nimport (\n    \"sync\"\n)\n\n// For frequent reads, infrequent writes\ntype Cache struct {\n    m sync.Map\n}\n\nfunc (c *Cache) Get(key string) (interface{}, bool) {\n    return c.m.Load(key)\n}\n\nfunc (c *Cache) Set(key string, value interface{}) {\n    c.m.Store(key, value)\n}\n\nfunc (c *Cache) GetOrSet(key string, value interface{}) (interface{}, bool) {\n    return c.m.LoadOrStore(key, value)\n}\n\nfunc (c *Cache) Delete(key string) {\n    c.m.Delete(key)\n}\n\n// For write-heavy workloads, use sharded map\ntype ShardedMap struct {\n    shards    []*shard\n    numShards int\n}\n\ntype shard struct {\n    sync.RWMutex\n    data map[string]interface{}\n}\n\nfunc NewShardedMap(numShards int) *ShardedMap {\n    m := &ShardedMap{\n        shards:    make([]*shard, numShards),\n        numShards: numShards,\n    }\n    for i := range m.shards {\n        m.shards[i] = &shard{data: make(map[string]interface{})}\n    }\n    return m\n}\n\nfunc (m *ShardedMap) getShard(key string) *shard {\n    // Simple hash\n    h := 0\n    for _, c := range key {\n        h = 31*h + int(c)\n    }\n    return m.shards[h%m.numShards]\n}\n\nfunc (m *ShardedMap) Get(key string) (interface{}, bool) {\n    shard := m.getShard(key)\n    shard.RLock()\n    defer shard.RUnlock()\n    v, ok := shard.data[key]\n    return v, ok\n}\n\nfunc (m *ShardedMap) Set(key string, value interface{}) {\n    shard := m.getShard(key)\n    shard.Lock()\n    defer shard.Unlock()\n    shard.data[key] = value\n}\n```\n\n### Pattern 7: Select with Timeout and Default\n\n```go\nfunc selectPatterns() {\n    ch := make(chan int)\n\n    // Timeout pattern\n    select {\n    case v := <-ch:\n        fmt.Println(\"Received:\", v)\n    case <-time.After(time.Second):\n        fmt.Println(\"Timeout!\")\n    }\n\n    // Non-blocking send/receive\n    select {\n    case ch <- 42:\n        fmt.Println(\"Sent\")\n    default:\n        fmt.Println(\"Channel full, skipping\")\n    }\n\n    // Priority select (check high priority first)\n    highPriority := make(chan int)\n    lowPriority := make(chan int)\n\n    for {\n        select {\n        case msg := <-highPriority:\n            fmt.Println(\"High priority:\", msg)\n        default:\n            select {\n            case msg := <-highPriority:\n                fmt.Println(\"High priority:\", msg)\n            case msg := <-lowPriority:\n                fmt.Println(\"Low priority:\", msg)\n            }\n        }\n    }\n}\n```\n\n## Race Detection\n\n```bash\n# Run tests with race detector\ngo test -race ./...\n\n# Build with race detector\ngo build -race .\n\n# Run with race detector\ngo run -race main.go\n```\n\n## Best Practices\n\n### Do's\n- **Use context** - For cancellation and deadlines\n- **Close channels** - From sender side only\n- **Use errgroup** - For concurrent operations with errors\n- **Buffer channels** - When you know the count\n- **Prefer channels** - Over mutexes when possible\n\n### Don'ts\n- **Don't leak goroutines** - Always have exit path\n- **Don't close from receiver** - Causes panic\n- **Don't use shared memory** - Unless necessary\n- **Don't ignore context cancellation** - Check ctx.Done()\n- **Don't use time.Sleep for sync** - Use proper primitives\n\n## Resources\n\n- [Go Concurrency Patterns](https://go.dev/blog/pipelines)\n- [Effective Go - Concurrency](https://go.dev/doc/effective_go#concurrency)\n- [Go by Example - Goroutines](https://gobyexample.com/goroutines)\n"
}