{
  "id": "quantitative_trading_risk_metrics_calculation",
  "name": "risk-metrics-calculation",
  "source": "quantitative-trading",
  "originalPath": "plugins/quantitative-trading/skills/risk-metrics-calculation/SKILL.md",
  "activationCriteria": "Calculate portfolio risk metrics including VaR, CVaR, Sharpe, Sortino, and drawdown analysis. Use when measuring portfolio risk, implementing risk limits, or building risk monitoring systems.",
  "tier1_metadata": "risk-metrics-calculation: Calculate portfolio risk metrics including VaR, CVaR, Sharpe, Sortino, and drawdown analysis. Use wh",
  "tier2_instructions": "# Risk Metrics Calculation\n\nComprehensive risk measurement toolkit for portfolio management, including Value at Risk, Expected Shortfall, and drawdown analysis.\n\n## When to Use This Skill\n\n- Measuring portfolio risk\n- Implementing risk limits\n- Building risk dashboards\n- Calculating risk-adjusted returns\n- Setting position sizes\n- Regulatory reporting\n\n## Core Concepts\n\n### 1. Risk Metric Categories\n\n| Category | Metrics | Use Case |\n|----------|---------|----------|\n| **Volatility** | Std Dev, Beta | General risk |\n| **Tail Risk** | VaR, CVaR | Extreme losses |\n| **Drawdown** | Max DD, Calmar | Capital preservation |\n| **Risk-Adjusted** | Sharpe, Sortino | Performance |\n\n### 2. Time Horizons\n\n```\nIntraday:   Minute/hourly VaR for day traders\nDaily:      Standard risk reporting\nWeekly:     Rebalancing decisions\nMonthly:    Performance attribution\nAnnual:     Strategic allocation\n```\n\n## Implementation\n\n### Pattern 1: Core Risk Metrics\n\n```python\nimport numpy as np\nimport pandas as pd\nfrom scipy import stats\nfrom typing import Dict, Optional, Tuple\n\nclass RiskMetrics:\n    \"\"\"Core risk metric calculations.\"\"\"\n\n    def __init__(self, returns: pd.Series, rf_rate: float = 0.02):\n        \"\"\"\n        Args:\n            returns: Series of periodic returns\n            rf_rate: Annual risk-free rate\n        \"\"\"\n        self.returns = returns\n        self.rf_rate = rf_rate\n        self.ann_factor = 252  # Trading days per year\n\n    # Volatility Metrics\n    def volatility(self, annualized: bool = True) -> float:\n        \"\"\"Standard deviation of returns.\"\"\"\n        vol = self.returns.std()\n        if annualized:\n            vol *= np.sqrt(self.ann_factor)\n        return vol\n\n    def downside_deviation(self, threshold: float = 0, annualized: bool = True) -> float:\n        \"\"\"Standard deviation of returns below threshold.\"\"\"\n        downside = self.returns[self.returns < threshold]\n        if len(downside) == 0:\n            return 0.0\n        dd = downside.std()\n        if annualiz",
  "tier3_resources": "ed:\n            dd *= np.sqrt(self.ann_factor)\n        return dd\n\n    def beta(self, market_returns: pd.Series) -> float:\n        \"\"\"Beta relative to market.\"\"\"\n        aligned = pd.concat([self.returns, market_returns], axis=1).dropna()\n        if len(aligned) < 2:\n            return np.nan\n        cov = np.cov(aligned.iloc[:, 0], aligned.iloc[:, 1])\n        return cov[0, 1] / cov[1, 1] if cov[1, 1] != 0 else 0\n\n    # Value at Risk\n    def var_historical(self, confidence: float = 0.95) -> float:\n        \"\"\"Historical VaR at confidence level.\"\"\"\n        return -np.percentile(self.returns, (1 - confidence) * 100)\n\n    def var_parametric(self, confidence: float = 0.95) -> float:\n        \"\"\"Parametric VaR assuming normal distribution.\"\"\"\n        z_score = stats.norm.ppf(confidence)\n        return self.returns.mean() - z_score * self.returns.std()\n\n    def var_cornish_fisher(self, confidence: float = 0.95) -> float:\n        \"\"\"VaR with Cornish-Fisher expansion for non-normality.\"\"\"\n        z = stats.norm.ppf(confidence)\n        s = stats.skew(self.returns)  # Skewness\n        k = stats.kurtosis(self.returns)  # Excess kurtosis\n\n        # Cornish-Fisher expansion\n        z_cf = (z + (z**2 - 1) * s / 6 +\n                (z**3 - 3*z) * k / 24 -\n                (2*z**3 - 5*z) * s**2 / 36)\n\n        return -(self.returns.mean() + z_cf * self.returns.std())\n\n    # Conditional VaR (Expected Shortfall)\n    def cvar(self, confidence: float = 0.95) -> float:\n        \"\"\"Expected Shortfall / CVaR / Average VaR.\"\"\"\n        var = self.var_historical(confidence)\n        return -self.returns[self.returns <= -var].mean()\n\n    # Drawdown Analysis\n    def drawdowns(self) -> pd.Series:\n        \"\"\"Calculate drawdown series.\"\"\"\n        cumulative = (1 + self.returns).cumprod()\n        running_max = cumulative.cummax()\n        return (cumulative - running_max) / running_max\n\n    def max_drawdown(self) -> float:\n        \"\"\"Maximum drawdown.\"\"\"\n        return self.drawdowns().min()\n\n    def avg_drawdown(self) -> float:\n        \"\"\"Average drawdown.\"\"\"\n        dd = self.drawdowns()\n        return dd[dd < 0].mean() if (dd < 0).any() else 0\n\n    def drawdown_duration(self) -> Dict[str, int]:\n        \"\"\"Drawdown duration statistics.\"\"\"\n        dd = self.drawdowns()\n        in_drawdown = dd < 0\n\n        # Find drawdown periods\n        drawdown_starts = in_drawdown & ~in_drawdown.shift(1).fillna(False)\n        drawdown_ends = ~in_drawdown & in_drawdown.shift(1).fillna(False)\n\n        durations = []\n        current_duration = 0\n\n        for i in range(len(dd)):\n            if in_drawdown.iloc[i]:\n                current_duration += 1\n            elif current_duration > 0:\n                durations.append(current_duration)\n                current_duration = 0\n\n        if current_duration > 0:\n            durations.append(current_duration)\n\n        return {\n            \"max_duration\": max(durations) if durations else 0,\n            \"avg_duration\": np.mean(durations) if durations else 0",
  "tokenEstimate": {
    "tier1": 19.5,
    "tier2": 331.5,
    "tier3": 2003.3000000000002
  },
  "fullDefinition": "---\nname: risk-metrics-calculation\ndescription: Calculate portfolio risk metrics including VaR, CVaR, Sharpe, Sortino, and drawdown analysis. Use when measuring portfolio risk, implementing risk limits, or building risk monitoring systems.\n---\n\n# Risk Metrics Calculation\n\nComprehensive risk measurement toolkit for portfolio management, including Value at Risk, Expected Shortfall, and drawdown analysis.\n\n## When to Use This Skill\n\n- Measuring portfolio risk\n- Implementing risk limits\n- Building risk dashboards\n- Calculating risk-adjusted returns\n- Setting position sizes\n- Regulatory reporting\n\n## Core Concepts\n\n### 1. Risk Metric Categories\n\n| Category | Metrics | Use Case |\n|----------|---------|----------|\n| **Volatility** | Std Dev, Beta | General risk |\n| **Tail Risk** | VaR, CVaR | Extreme losses |\n| **Drawdown** | Max DD, Calmar | Capital preservation |\n| **Risk-Adjusted** | Sharpe, Sortino | Performance |\n\n### 2. Time Horizons\n\n```\nIntraday:   Minute/hourly VaR for day traders\nDaily:      Standard risk reporting\nWeekly:     Rebalancing decisions\nMonthly:    Performance attribution\nAnnual:     Strategic allocation\n```\n\n## Implementation\n\n### Pattern 1: Core Risk Metrics\n\n```python\nimport numpy as np\nimport pandas as pd\nfrom scipy import stats\nfrom typing import Dict, Optional, Tuple\n\nclass RiskMetrics:\n    \"\"\"Core risk metric calculations.\"\"\"\n\n    def __init__(self, returns: pd.Series, rf_rate: float = 0.02):\n        \"\"\"\n        Args:\n            returns: Series of periodic returns\n            rf_rate: Annual risk-free rate\n        \"\"\"\n        self.returns = returns\n        self.rf_rate = rf_rate\n        self.ann_factor = 252  # Trading days per year\n\n    # Volatility Metrics\n    def volatility(self, annualized: bool = True) -> float:\n        \"\"\"Standard deviation of returns.\"\"\"\n        vol = self.returns.std()\n        if annualized:\n            vol *= np.sqrt(self.ann_factor)\n        return vol\n\n    def downside_deviation(self, threshold: float = 0, annualized: bool = True) -> float:\n        \"\"\"Standard deviation of returns below threshold.\"\"\"\n        downside = self.returns[self.returns < threshold]\n        if len(downside) == 0:\n            return 0.0\n        dd = downside.std()\n        if annualized:\n            dd *= np.sqrt(self.ann_factor)\n        return dd\n\n    def beta(self, market_returns: pd.Series) -> float:\n        \"\"\"Beta relative to market.\"\"\"\n        aligned = pd.concat([self.returns, market_returns], axis=1).dropna()\n        if len(aligned) < 2:\n            return np.nan\n        cov = np.cov(aligned.iloc[:, 0], aligned.iloc[:, 1])\n        return cov[0, 1] / cov[1, 1] if cov[1, 1] != 0 else 0\n\n    # Value at Risk\n    def var_historical(self, confidence: float = 0.95) -> float:\n        \"\"\"Historical VaR at confidence level.\"\"\"\n        return -np.percentile(self.returns, (1 - confidence) * 100)\n\n    def var_parametric(self, confidence: float = 0.95) -> float:\n        \"\"\"Parametric VaR assuming normal distribution.\"\"\"\n        z_score = stats.norm.ppf(confidence)\n        return self.returns.mean() - z_score * self.returns.std()\n\n    def var_cornish_fisher(self, confidence: float = 0.95) -> float:\n        \"\"\"VaR with Cornish-Fisher expansion for non-normality.\"\"\"\n        z = stats.norm.ppf(confidence)\n        s = stats.skew(self.returns)  # Skewness\n        k = stats.kurtosis(self.returns)  # Excess kurtosis\n\n        # Cornish-Fisher expansion\n        z_cf = (z + (z**2 - 1) * s / 6 +\n                (z**3 - 3*z) * k / 24 -\n                (2*z**3 - 5*z) * s**2 / 36)\n\n        return -(self.returns.mean() + z_cf * self.returns.std())\n\n    # Conditional VaR (Expected Shortfall)\n    def cvar(self, confidence: float = 0.95) -> float:\n        \"\"\"Expected Shortfall / CVaR / Average VaR.\"\"\"\n        var = self.var_historical(confidence)\n        return -self.returns[self.returns <= -var].mean()\n\n    # Drawdown Analysis\n    def drawdowns(self) -> pd.Series:\n        \"\"\"Calculate drawdown series.\"\"\"\n        cumulative = (1 + self.returns).cumprod()\n        running_max = cumulative.cummax()\n        return (cumulative - running_max) / running_max\n\n    def max_drawdown(self) -> float:\n        \"\"\"Maximum drawdown.\"\"\"\n        return self.drawdowns().min()\n\n    def avg_drawdown(self) -> float:\n        \"\"\"Average drawdown.\"\"\"\n        dd = self.drawdowns()\n        return dd[dd < 0].mean() if (dd < 0).any() else 0\n\n    def drawdown_duration(self) -> Dict[str, int]:\n        \"\"\"Drawdown duration statistics.\"\"\"\n        dd = self.drawdowns()\n        in_drawdown = dd < 0\n\n        # Find drawdown periods\n        drawdown_starts = in_drawdown & ~in_drawdown.shift(1).fillna(False)\n        drawdown_ends = ~in_drawdown & in_drawdown.shift(1).fillna(False)\n\n        durations = []\n        current_duration = 0\n\n        for i in range(len(dd)):\n            if in_drawdown.iloc[i]:\n                current_duration += 1\n            elif current_duration > 0:\n                durations.append(current_duration)\n                current_duration = 0\n\n        if current_duration > 0:\n            durations.append(current_duration)\n\n        return {\n            \"max_duration\": max(durations) if durations else 0,\n            \"avg_duration\": np.mean(durations) if durations else 0,\n            \"current_duration\": current_duration\n        }\n\n    # Risk-Adjusted Returns\n    def sharpe_ratio(self) -> float:\n        \"\"\"Annualized Sharpe ratio.\"\"\"\n        excess_return = self.returns.mean() * self.ann_factor - self.rf_rate\n        vol = self.volatility(annualized=True)\n        return excess_return / vol if vol > 0 else 0\n\n    def sortino_ratio(self) -> float:\n        \"\"\"Sortino ratio using downside deviation.\"\"\"\n        excess_return = self.returns.mean() * self.ann_factor - self.rf_rate\n        dd = self.downside_deviation(threshold=0, annualized=True)\n        return excess_return / dd if dd > 0 else 0\n\n    def calmar_ratio(self) -> float:\n        \"\"\"Calmar ratio (return / max drawdown).\"\"\"\n        annual_return = (1 + self.returns).prod() ** (self.ann_factor / len(self.returns)) - 1\n        max_dd = abs(self.max_drawdown())\n        return annual_return / max_dd if max_dd > 0 else 0\n\n    def omega_ratio(self, threshold: float = 0) -> float:\n        \"\"\"Omega ratio.\"\"\"\n        returns_above = self.returns[self.returns > threshold] - threshold\n        returns_below = threshold - self.returns[self.returns <= threshold]\n\n        if returns_below.sum() == 0:\n            return np.inf\n\n        return returns_above.sum() / returns_below.sum()\n\n    # Information Ratio\n    def information_ratio(self, benchmark_returns: pd.Series) -> float:\n        \"\"\"Information ratio vs benchmark.\"\"\"\n        active_returns = self.returns - benchmark_returns\n        tracking_error = active_returns.std() * np.sqrt(self.ann_factor)\n        active_return = active_returns.mean() * self.ann_factor\n        return active_return / tracking_error if tracking_error > 0 else 0\n\n    # Summary\n    def summary(self) -> Dict[str, float]:\n        \"\"\"Generate comprehensive risk summary.\"\"\"\n        dd_stats = self.drawdown_duration()\n\n        return {\n            # Returns\n            \"total_return\": (1 + self.returns).prod() - 1,\n            \"annual_return\": (1 + self.returns).prod() ** (self.ann_factor / len(self.returns)) - 1,\n\n            # Volatility\n            \"annual_volatility\": self.volatility(),\n            \"downside_deviation\": self.downside_deviation(),\n\n            # VaR & CVaR\n            \"var_95_historical\": self.var_historical(0.95),\n            \"var_99_historical\": self.var_historical(0.99),\n            \"cvar_95\": self.cvar(0.95),\n\n            # Drawdowns\n            \"max_drawdown\": self.max_drawdown(),\n            \"avg_drawdown\": self.avg_drawdown(),\n            \"max_drawdown_duration\": dd_stats[\"max_duration\"],\n\n            # Risk-Adjusted\n            \"sharpe_ratio\": self.sharpe_ratio(),\n            \"sortino_ratio\": self.sortino_ratio(),\n            \"calmar_ratio\": self.calmar_ratio(),\n            \"omega_ratio\": self.omega_ratio(),\n\n            # Distribution\n            \"skewness\": stats.skew(self.returns),\n            \"kurtosis\": stats.kurtosis(self.returns),\n        }\n```\n\n### Pattern 2: Portfolio Risk\n\n```python\nclass PortfolioRisk:\n    \"\"\"Portfolio-level risk calculations.\"\"\"\n\n    def __init__(\n        self,\n        returns: pd.DataFrame,\n        weights: Optional[pd.Series] = None\n    ):\n        \"\"\"\n        Args:\n            returns: DataFrame with asset returns (columns = assets)\n            weights: Portfolio weights (default: equal weight)\n        \"\"\"\n        self.returns = returns\n        self.weights = weights if weights is not None else \\\n            pd.Series(1/len(returns.columns), index=returns.columns)\n        self.ann_factor = 252\n\n    def portfolio_return(self) -> float:\n        \"\"\"Weighted portfolio return.\"\"\"\n        return (self.returns @ self.weights).mean() * self.ann_factor\n\n    def portfolio_volatility(self) -> float:\n        \"\"\"Portfolio volatility.\"\"\"\n        cov_matrix = self.returns.cov() * self.ann_factor\n        port_var = self.weights @ cov_matrix @ self.weights\n        return np.sqrt(port_var)\n\n    def marginal_risk_contribution(self) -> pd.Series:\n        \"\"\"Marginal contribution to risk by asset.\"\"\"\n        cov_matrix = self.returns.cov() * self.ann_factor\n        port_vol = self.portfolio_volatility()\n\n        # Marginal contribution\n        mrc = (cov_matrix @ self.weights) / port_vol\n        return mrc\n\n    def component_risk(self) -> pd.Series:\n        \"\"\"Component contribution to total risk.\"\"\"\n        mrc = self.marginal_risk_contribution()\n        return self.weights * mrc\n\n    def risk_parity_weights(self, target_vol: float = None) -> pd.Series:\n        \"\"\"Calculate risk parity weights.\"\"\"\n        from scipy.optimize import minimize\n\n        n = len(self.returns.columns)\n        cov_matrix = self.returns.cov() * self.ann_factor\n\n        def risk_budget_objective(weights):\n            port_vol = np.sqrt(weights @ cov_matrix @ weights)\n            mrc = (cov_matrix @ weights) / port_vol\n            rc = weights * mrc\n            target_rc = port_vol / n  # Equal risk contribution\n            return np.sum((rc - target_rc) ** 2)\n\n        constraints = [\n            {\"type\": \"eq\", \"fun\": lambda w: np.sum(w) - 1},  # Weights sum to 1\n        ]\n        bounds = [(0.01, 1.0) for _ in range(n)]  # Min 1%, max 100%\n        x0 = np.array([1/n] * n)\n\n        result = minimize(\n            risk_budget_objective,\n            x0,\n            method=\"SLSQP\",\n            bounds=bounds,\n            constraints=constraints\n        )\n\n        return pd.Series(result.x, index=self.returns.columns)\n\n    def correlation_matrix(self) -> pd.DataFrame:\n        \"\"\"Asset correlation matrix.\"\"\"\n        return self.returns.corr()\n\n    def diversification_ratio(self) -> float:\n        \"\"\"Diversification ratio (higher = more diversified).\"\"\"\n        asset_vols = self.returns.std() * np.sqrt(self.ann_factor)\n        weighted_vol = (self.weights * asset_vols).sum()\n        port_vol = self.portfolio_volatility()\n        return weighted_vol / port_vol if port_vol > 0 else 1\n\n    def tracking_error(self, benchmark_returns: pd.Series) -> float:\n        \"\"\"Tracking error vs benchmark.\"\"\"\n        port_returns = self.returns @ self.weights\n        active_returns = port_returns - benchmark_returns\n        return active_returns.std() * np.sqrt(self.ann_factor)\n\n    def conditional_correlation(\n        self,\n        threshold_percentile: float = 10\n    ) -> pd.DataFrame:\n        \"\"\"Correlation during stress periods.\"\"\"\n        port_returns = self.returns @ self.weights\n        threshold = np.percentile(port_returns, threshold_percentile)\n        stress_mask = port_returns <= threshold\n        return self.returns[stress_mask].corr()\n```\n\n### Pattern 3: Rolling Risk Metrics\n\n```python\nclass RollingRiskMetrics:\n    \"\"\"Rolling window risk calculations.\"\"\"\n\n    def __init__(self, returns: pd.Series, window: int = 63):\n        \"\"\"\n        Args:\n            returns: Return series\n            window: Rolling window size (default: 63 = ~3 months)\n        \"\"\"\n        self.returns = returns\n        self.window = window\n\n    def rolling_volatility(self, annualized: bool = True) -> pd.Series:\n        \"\"\"Rolling volatility.\"\"\"\n        vol = self.returns.rolling(self.window).std()\n        if annualized:\n            vol *= np.sqrt(252)\n        return vol\n\n    def rolling_sharpe(self, rf_rate: float = 0.02) -> pd.Series:\n        \"\"\"Rolling Sharpe ratio.\"\"\"\n        rolling_return = self.returns.rolling(self.window).mean() * 252\n        rolling_vol = self.rolling_volatility()\n        return (rolling_return - rf_rate) / rolling_vol\n\n    def rolling_var(self, confidence: float = 0.95) -> pd.Series:\n        \"\"\"Rolling historical VaR.\"\"\"\n        return self.returns.rolling(self.window).apply(\n            lambda x: -np.percentile(x, (1 - confidence) * 100),\n            raw=True\n        )\n\n    def rolling_max_drawdown(self) -> pd.Series:\n        \"\"\"Rolling maximum drawdown.\"\"\"\n        def max_dd(returns):\n            cumulative = (1 + returns).cumprod()\n            running_max = cumulative.cummax()\n            drawdowns = (cumulative - running_max) / running_max\n            return drawdowns.min()\n\n        return self.returns.rolling(self.window).apply(max_dd, raw=False)\n\n    def rolling_beta(self, market_returns: pd.Series) -> pd.Series:\n        \"\"\"Rolling beta vs market.\"\"\"\n        def calc_beta(window_data):\n            port_ret = window_data.iloc[:, 0]\n            mkt_ret = window_data.iloc[:, 1]\n            cov = np.cov(port_ret, mkt_ret)\n            return cov[0, 1] / cov[1, 1] if cov[1, 1] != 0 else 0\n\n        combined = pd.concat([self.returns, market_returns], axis=1)\n        return combined.rolling(self.window).apply(\n            lambda x: calc_beta(x.to_frame()),\n            raw=False\n        ).iloc[:, 0]\n\n    def volatility_regime(\n        self,\n        low_threshold: float = 0.10,\n        high_threshold: float = 0.20\n    ) -> pd.Series:\n        \"\"\"Classify volatility regime.\"\"\"\n        vol = self.rolling_volatility()\n\n        def classify(v):\n            if v < low_threshold:\n                return \"low\"\n            elif v > high_threshold:\n                return \"high\"\n            else:\n                return \"normal\"\n\n        return vol.apply(classify)\n```\n\n### Pattern 4: Stress Testing\n\n```python\nclass StressTester:\n    \"\"\"Historical and hypothetical stress testing.\"\"\"\n\n    # Historical crisis periods\n    HISTORICAL_SCENARIOS = {\n        \"2008_financial_crisis\": (\"2008-09-01\", \"2009-03-31\"),\n        \"2020_covid_crash\": (\"2020-02-19\", \"2020-03-23\"),\n        \"2022_rate_hikes\": (\"2022-01-01\", \"2022-10-31\"),\n        \"dot_com_bust\": (\"2000-03-01\", \"2002-10-01\"),\n        \"flash_crash_2010\": (\"2010-05-06\", \"2010-05-06\"),\n    }\n\n    def __init__(self, returns: pd.Series, weights: pd.Series = None):\n        self.returns = returns\n        self.weights = weights\n\n    def historical_stress_test(\n        self,\n        scenario_name: str,\n        historical_data: pd.DataFrame\n    ) -> Dict[str, float]:\n        \"\"\"Test portfolio against historical crisis period.\"\"\"\n        if scenario_name not in self.HISTORICAL_SCENARIOS:\n            raise ValueError(f\"Unknown scenario: {scenario_name}\")\n\n        start, end = self.HISTORICAL_SCENARIOS[scenario_name]\n\n        # Get returns during crisis\n        crisis_returns = historical_data.loc[start:end]\n\n        if self.weights is not None:\n            port_returns = (crisis_returns @ self.weights)\n        else:\n            port_returns = crisis_returns\n\n        total_return = (1 + port_returns).prod() - 1\n        max_dd = self._calculate_max_dd(port_returns)\n        worst_day = port_returns.min()\n\n        return {\n            \"scenario\": scenario_name,\n            \"period\": f\"{start} to {end}\",\n            \"total_return\": total_return,\n            \"max_drawdown\": max_dd,\n            \"worst_day\": worst_day,\n            \"volatility\": port_returns.std() * np.sqrt(252)\n        }\n\n    def hypothetical_stress_test(\n        self,\n        shocks: Dict[str, float]\n    ) -> float:\n        \"\"\"\n        Test portfolio against hypothetical shocks.\n\n        Args:\n            shocks: Dict of {asset: shock_return}\n        \"\"\"\n        if self.weights is None:\n            raise ValueError(\"Weights required for hypothetical stress test\")\n\n        total_impact = 0\n        for asset, shock in shocks.items():\n            if asset in self.weights.index:\n                total_impact += self.weights[asset] * shock\n\n        return total_impact\n\n    def monte_carlo_stress(\n        self,\n        n_simulations: int = 10000,\n        horizon_days: int = 21,\n        vol_multiplier: float = 2.0\n    ) -> Dict[str, float]:\n        \"\"\"Monte Carlo stress test with elevated volatility.\"\"\"\n        mean = self.returns.mean()\n        vol = self.returns.std() * vol_multiplier\n\n        simulations = np.random.normal(\n            mean,\n            vol,\n            (n_simulations, horizon_days)\n        )\n\n        total_returns = (1 + simulations).prod(axis=1) - 1\n\n        return {\n            \"expected_loss\": -total_returns.mean(),\n            \"var_95\": -np.percentile(total_returns, 5),\n            \"var_99\": -np.percentile(total_returns, 1),\n            \"worst_case\": -total_returns.min(),\n            \"prob_10pct_loss\": (total_returns < -0.10).mean()\n        }\n\n    def _calculate_max_dd(self, returns: pd.Series) -> float:\n        cumulative = (1 + returns).cumprod()\n        running_max = cumulative.cummax()\n        drawdowns = (cumulative - running_max) / running_max\n        return drawdowns.min()\n```\n\n## Quick Reference\n\n```python\n# Daily usage\nmetrics = RiskMetrics(returns)\nprint(f\"Sharpe: {metrics.sharpe_ratio():.2f}\")\nprint(f\"Max DD: {metrics.max_drawdown():.2%}\")\nprint(f\"VaR 95%: {metrics.var_historical(0.95):.2%}\")\n\n# Full summary\nsummary = metrics.summary()\nfor metric, value in summary.items():\n    print(f\"{metric}: {value:.4f}\")\n```\n\n## Best Practices\n\n### Do's\n- **Use multiple metrics** - No single metric captures all risk\n- **Consider tail risk** - VaR isn't enough, use CVaR\n- **Rolling analysis** - Risk changes over time\n- **Stress test** - Historical and hypothetical\n- **Document assumptions** - Distribution, lookback, etc.\n\n### Don'ts\n- **Don't rely on VaR alone** - Underestimates tail risk\n- **Don't assume normality** - Returns are fat-tailed\n- **Don't ignore correlation** - Increases in stress\n- **Don't use short lookbacks** - Miss regime changes\n- **Don't forget transaction costs** - Affects realized risk\n\n## Resources\n\n- [Risk Management and Financial Institutions (John Hull)](https://www.amazon.com/Risk-Management-Financial-Institutions-5th/dp/1119448115)\n- [Quantitative Risk Management (McNeil, Frey, Embrechts)](https://www.amazon.com/Quantitative-Risk-Management-Techniques-Princeton/dp/0691166277)\n- [pyfolio Documentation](https://quantopian.github.io/pyfolio/)\n"
}