{
  "id": "data_engineering_dbt_transformation_patterns",
  "name": "dbt-transformation-patterns",
  "source": "data-engineering",
  "originalPath": "plugins/data-engineering/skills/dbt-transformation-patterns/SKILL.md",
  "activationCriteria": "Master dbt (data build tool) for analytics engineering with model organization, testing, documentation, and incremental strategies. Use when building data transformations, creating data models, or imp",
  "tier1_metadata": "dbt-transformation-patterns: Master dbt (data build tool) for analytics engineering with model organization, testing, documentati",
  "tier2_instructions": "# dbt Transformation Patterns\n\nProduction-ready patterns for dbt (data build tool) including model organization, testing strategies, documentation, and incremental processing.\n\n## When to Use This Skill\n\n- Building data transformation pipelines with dbt\n- Organizing models into staging, intermediate, and marts layers\n- Implementing data quality tests\n- Creating incremental models for large datasets\n- Documenting data models and lineage\n- Setting up dbt project structure\n\n## Core Concepts\n\n### 1. Model Layers (Medallion Architecture)\n\n```\nsources/          Raw data definitions\n    \u2193\nstaging/          1:1 with source, light cleaning\n    \u2193\nintermediate/     Business logic, joins, aggregations\n    \u2193\nmarts/            Final analytics tables\n```\n\n### 2. Naming Conventions\n\n| Layer | Prefix | Example |\n|-------|--------|---------|\n| Staging | `stg_` | `stg_stripe__payments` |\n| Intermediate | `int_` | `int_payments_pivoted` |\n| Marts | `dim_`, `fct_` | `dim_customers`, `fct_orders` |\n\n## Quick Start\n\n```yaml\n# dbt_project.yml\nname: 'analytics'\nversion: '1.0.0'\nprofile: 'analytics'\n\nmodel-paths: [\"models\"]\nanalysis-paths: [\"analyses\"]\ntest-paths: [\"tests\"]\nseed-paths: [\"seeds\"]\nmacro-paths: [\"macros\"]\n\nvars:\n  start_date: '2020-01-01'\n\nmodels:\n  analytics:\n    staging:\n      +materialized: view\n      +schema: staging\n    intermediate:\n      +materialized: ephemeral\n    marts:\n      +materialized: table\n      +schema: analytics\n```\n\n```\n# Project structure\nmodels/\n\u251c\u2500\u2500 staging/\n\u2502   \u251c\u2500\u2500 stripe/\n\u2502   \u2502   \u251c\u2500\u2500 _stripe__sources.yml\n\u2502   \u2502   \u251c\u2500\u2500 _stripe__models.yml\n\u2502   \u2502   \u251c\u2500\u2500 stg_stripe__customers.sql\n\u2502   \u2502   \u2514\u2500\u2500 stg_stripe__payments.sql\n\u2502   \u2514\u2500\u2500 shopify/\n\u2502       \u251c\u2500\u2500 _shopify__sources.yml\n\u2502       \u2514\u2500\u2500 stg_shopify__orders.sql\n\u251c\u2500\u2500 intermediate/\n\u2502   \u2514\u2500\u2500 finance/\n\u2502       \u2514\u2500\u2500 int_payments_pivoted.sql\n\u2514\u2500\u2500 marts/\n    \u251c\u2500\u2500 core/\n    \u2502   \u251c\u2500\u2500 _core__models.yml\n    \u2502   \u251c\u2500\u2500 dim_customers.sql\n    \u2502   \u2514\u2500\u2500 fct_orders.sql\n    \u2514\u2500\u2500 finance/\n        \u2514\u2500\u2500 fct_revenue.sql\n```\n\n## Patterns\n\n### Pattern 1: So",
  "tier3_resources": "urce Definitions\n\n```yaml\n# models/staging/stripe/_stripe__sources.yml\nversion: 2\n\nsources:\n  - name: stripe\n    description: Raw Stripe data loaded via Fivetran\n    database: raw\n    schema: stripe\n    loader: fivetran\n    loaded_at_field: _fivetran_synced\n    freshness:\n      warn_after: {count: 12, period: hour}\n      error_after: {count: 24, period: hour}\n    tables:\n      - name: customers\n        description: Stripe customer records\n        columns:\n          - name: id\n            description: Primary key\n            tests:\n              - unique\n              - not_null\n          - name: email\n            description: Customer email\n          - name: created\n            description: Account creation timestamp\n\n      - name: payments\n        description: Stripe payment transactions\n        columns:\n          - name: id\n            tests:\n              - unique\n              - not_null\n          - name: customer_id\n            tests:\n              - not_null\n              - relationships:\n                  to: source('stripe', 'customers')\n                  field: id\n```\n\n### Pattern 2: Staging Models\n\n```sql\n-- models/staging/stripe/stg_stripe__customers.sql\nwith source as (\n    select * from {{ source('stripe', 'customers') }}\n),\n\nrenamed as (\n    select\n        -- ids\n        id as customer_id,\n\n        -- strings\n        lower(email) as email,\n        name as customer_name,\n\n        -- timestamps\n        created as created_at,\n\n        -- metadata\n        _fivetran_synced as _loaded_at\n\n    from source\n)\n\nselect * from renamed\n```\n\n```sql\n-- models/staging/stripe/stg_stripe__payments.sql\n{{\n    config(\n        materialized='incremental',\n        unique_key='payment_id',\n        on_schema_change='append_new_columns'\n    )\n}}\n\nwith source as (\n    select * from {{ source('stripe', 'payments') }}\n\n    {% if is_incremental() %}\n    where _fivetran_synced > (select max(_loaded_at) from {{ this }})\n    {% endif %}\n),\n\nrenamed as (\n    select\n        -- ids\n        id as payment_id,\n        customer_id,\n        invoice_id,\n\n        -- amounts (convert cents to dollars)\n        amount / 100.0 as amount,\n        amount_refunded / 100.0 as amount_refunded,\n\n        -- status\n        status as payment_status,\n\n        -- timestamps\n        created as created_at,\n\n        -- metadata\n        _fivetran_synced as _loaded_at\n\n    from source\n)\n\nselect * from renamed\n```\n\n### Pattern 3: Intermediate Models\n\n```sql\n-- models/intermediate/finance/int_payments_pivoted_to_customer.sql\nwith payments as (\n    select * from {{ ref('stg_stripe__payments') }}\n),\n\ncustomers as (\n    select * from {{ ref('stg_stripe__customers') }}\n),\n\npayment_summary as (\n    select\n        customer_id,\n        count(*) as total_payments,\n        count(case when payment_status = 'succeeded' then 1 end) as successful_payments,\n        sum(case when payment_status = 'succeeded' then amount else 0 end) as total_amount_paid,\n        min(created_at) as first_payment_at,\n        max(c",
  "tokenEstimate": {
    "tier1": 18.2,
    "tier2": 314.6,
    "tier3": 1453.4
  },
  "fullDefinition": "---\nname: dbt-transformation-patterns\ndescription: Master dbt (data build tool) for analytics engineering with model organization, testing, documentation, and incremental strategies. Use when building data transformations, creating data models, or implementing analytics engineering best practices.\n---\n\n# dbt Transformation Patterns\n\nProduction-ready patterns for dbt (data build tool) including model organization, testing strategies, documentation, and incremental processing.\n\n## When to Use This Skill\n\n- Building data transformation pipelines with dbt\n- Organizing models into staging, intermediate, and marts layers\n- Implementing data quality tests\n- Creating incremental models for large datasets\n- Documenting data models and lineage\n- Setting up dbt project structure\n\n## Core Concepts\n\n### 1. Model Layers (Medallion Architecture)\n\n```\nsources/          Raw data definitions\n    \u2193\nstaging/          1:1 with source, light cleaning\n    \u2193\nintermediate/     Business logic, joins, aggregations\n    \u2193\nmarts/            Final analytics tables\n```\n\n### 2. Naming Conventions\n\n| Layer | Prefix | Example |\n|-------|--------|---------|\n| Staging | `stg_` | `stg_stripe__payments` |\n| Intermediate | `int_` | `int_payments_pivoted` |\n| Marts | `dim_`, `fct_` | `dim_customers`, `fct_orders` |\n\n## Quick Start\n\n```yaml\n# dbt_project.yml\nname: 'analytics'\nversion: '1.0.0'\nprofile: 'analytics'\n\nmodel-paths: [\"models\"]\nanalysis-paths: [\"analyses\"]\ntest-paths: [\"tests\"]\nseed-paths: [\"seeds\"]\nmacro-paths: [\"macros\"]\n\nvars:\n  start_date: '2020-01-01'\n\nmodels:\n  analytics:\n    staging:\n      +materialized: view\n      +schema: staging\n    intermediate:\n      +materialized: ephemeral\n    marts:\n      +materialized: table\n      +schema: analytics\n```\n\n```\n# Project structure\nmodels/\n\u251c\u2500\u2500 staging/\n\u2502   \u251c\u2500\u2500 stripe/\n\u2502   \u2502   \u251c\u2500\u2500 _stripe__sources.yml\n\u2502   \u2502   \u251c\u2500\u2500 _stripe__models.yml\n\u2502   \u2502   \u251c\u2500\u2500 stg_stripe__customers.sql\n\u2502   \u2502   \u2514\u2500\u2500 stg_stripe__payments.sql\n\u2502   \u2514\u2500\u2500 shopify/\n\u2502       \u251c\u2500\u2500 _shopify__sources.yml\n\u2502       \u2514\u2500\u2500 stg_shopify__orders.sql\n\u251c\u2500\u2500 intermediate/\n\u2502   \u2514\u2500\u2500 finance/\n\u2502       \u2514\u2500\u2500 int_payments_pivoted.sql\n\u2514\u2500\u2500 marts/\n    \u251c\u2500\u2500 core/\n    \u2502   \u251c\u2500\u2500 _core__models.yml\n    \u2502   \u251c\u2500\u2500 dim_customers.sql\n    \u2502   \u2514\u2500\u2500 fct_orders.sql\n    \u2514\u2500\u2500 finance/\n        \u2514\u2500\u2500 fct_revenue.sql\n```\n\n## Patterns\n\n### Pattern 1: Source Definitions\n\n```yaml\n# models/staging/stripe/_stripe__sources.yml\nversion: 2\n\nsources:\n  - name: stripe\n    description: Raw Stripe data loaded via Fivetran\n    database: raw\n    schema: stripe\n    loader: fivetran\n    loaded_at_field: _fivetran_synced\n    freshness:\n      warn_after: {count: 12, period: hour}\n      error_after: {count: 24, period: hour}\n    tables:\n      - name: customers\n        description: Stripe customer records\n        columns:\n          - name: id\n            description: Primary key\n            tests:\n              - unique\n              - not_null\n          - name: email\n            description: Customer email\n          - name: created\n            description: Account creation timestamp\n\n      - name: payments\n        description: Stripe payment transactions\n        columns:\n          - name: id\n            tests:\n              - unique\n              - not_null\n          - name: customer_id\n            tests:\n              - not_null\n              - relationships:\n                  to: source('stripe', 'customers')\n                  field: id\n```\n\n### Pattern 2: Staging Models\n\n```sql\n-- models/staging/stripe/stg_stripe__customers.sql\nwith source as (\n    select * from {{ source('stripe', 'customers') }}\n),\n\nrenamed as (\n    select\n        -- ids\n        id as customer_id,\n\n        -- strings\n        lower(email) as email,\n        name as customer_name,\n\n        -- timestamps\n        created as created_at,\n\n        -- metadata\n        _fivetran_synced as _loaded_at\n\n    from source\n)\n\nselect * from renamed\n```\n\n```sql\n-- models/staging/stripe/stg_stripe__payments.sql\n{{\n    config(\n        materialized='incremental',\n        unique_key='payment_id',\n        on_schema_change='append_new_columns'\n    )\n}}\n\nwith source as (\n    select * from {{ source('stripe', 'payments') }}\n\n    {% if is_incremental() %}\n    where _fivetran_synced > (select max(_loaded_at) from {{ this }})\n    {% endif %}\n),\n\nrenamed as (\n    select\n        -- ids\n        id as payment_id,\n        customer_id,\n        invoice_id,\n\n        -- amounts (convert cents to dollars)\n        amount / 100.0 as amount,\n        amount_refunded / 100.0 as amount_refunded,\n\n        -- status\n        status as payment_status,\n\n        -- timestamps\n        created as created_at,\n\n        -- metadata\n        _fivetran_synced as _loaded_at\n\n    from source\n)\n\nselect * from renamed\n```\n\n### Pattern 3: Intermediate Models\n\n```sql\n-- models/intermediate/finance/int_payments_pivoted_to_customer.sql\nwith payments as (\n    select * from {{ ref('stg_stripe__payments') }}\n),\n\ncustomers as (\n    select * from {{ ref('stg_stripe__customers') }}\n),\n\npayment_summary as (\n    select\n        customer_id,\n        count(*) as total_payments,\n        count(case when payment_status = 'succeeded' then 1 end) as successful_payments,\n        sum(case when payment_status = 'succeeded' then amount else 0 end) as total_amount_paid,\n        min(created_at) as first_payment_at,\n        max(created_at) as last_payment_at\n    from payments\n    group by customer_id\n)\n\nselect\n    customers.customer_id,\n    customers.email,\n    customers.created_at as customer_created_at,\n    coalesce(payment_summary.total_payments, 0) as total_payments,\n    coalesce(payment_summary.successful_payments, 0) as successful_payments,\n    coalesce(payment_summary.total_amount_paid, 0) as lifetime_value,\n    payment_summary.first_payment_at,\n    payment_summary.last_payment_at\n\nfrom customers\nleft join payment_summary using (customer_id)\n```\n\n### Pattern 4: Mart Models (Dimensions and Facts)\n\n```sql\n-- models/marts/core/dim_customers.sql\n{{\n    config(\n        materialized='table',\n        unique_key='customer_id'\n    )\n}}\n\nwith customers as (\n    select * from {{ ref('int_payments_pivoted_to_customer') }}\n),\n\norders as (\n    select * from {{ ref('stg_shopify__orders') }}\n),\n\norder_summary as (\n    select\n        customer_id,\n        count(*) as total_orders,\n        sum(total_price) as total_order_value,\n        min(created_at) as first_order_at,\n        max(created_at) as last_order_at\n    from orders\n    group by customer_id\n),\n\nfinal as (\n    select\n        -- surrogate key\n        {{ dbt_utils.generate_surrogate_key(['customers.customer_id']) }} as customer_key,\n\n        -- natural key\n        customers.customer_id,\n\n        -- attributes\n        customers.email,\n        customers.customer_created_at,\n\n        -- payment metrics\n        customers.total_payments,\n        customers.successful_payments,\n        customers.lifetime_value,\n        customers.first_payment_at,\n        customers.last_payment_at,\n\n        -- order metrics\n        coalesce(order_summary.total_orders, 0) as total_orders,\n        coalesce(order_summary.total_order_value, 0) as total_order_value,\n        order_summary.first_order_at,\n        order_summary.last_order_at,\n\n        -- calculated fields\n        case\n            when customers.lifetime_value >= 1000 then 'high'\n            when customers.lifetime_value >= 100 then 'medium'\n            else 'low'\n        end as customer_tier,\n\n        -- timestamps\n        current_timestamp as _loaded_at\n\n    from customers\n    left join order_summary using (customer_id)\n)\n\nselect * from final\n```\n\n```sql\n-- models/marts/core/fct_orders.sql\n{{\n    config(\n        materialized='incremental',\n        unique_key='order_id',\n        incremental_strategy='merge'\n    )\n}}\n\nwith orders as (\n    select * from {{ ref('stg_shopify__orders') }}\n\n    {% if is_incremental() %}\n    where updated_at > (select max(updated_at) from {{ this }})\n    {% endif %}\n),\n\ncustomers as (\n    select * from {{ ref('dim_customers') }}\n),\n\nfinal as (\n    select\n        -- keys\n        orders.order_id,\n        customers.customer_key,\n        orders.customer_id,\n\n        -- dimensions\n        orders.order_status,\n        orders.fulfillment_status,\n        orders.payment_status,\n\n        -- measures\n        orders.subtotal,\n        orders.tax,\n        orders.shipping,\n        orders.total_price,\n        orders.total_discount,\n        orders.item_count,\n\n        -- timestamps\n        orders.created_at,\n        orders.updated_at,\n        orders.fulfilled_at,\n\n        -- metadata\n        current_timestamp as _loaded_at\n\n    from orders\n    left join customers on orders.customer_id = customers.customer_id\n)\n\nselect * from final\n```\n\n### Pattern 5: Testing and Documentation\n\n```yaml\n# models/marts/core/_core__models.yml\nversion: 2\n\nmodels:\n  - name: dim_customers\n    description: Customer dimension with payment and order metrics\n    columns:\n      - name: customer_key\n        description: Surrogate key for the customer dimension\n        tests:\n          - unique\n          - not_null\n\n      - name: customer_id\n        description: Natural key from source system\n        tests:\n          - unique\n          - not_null\n\n      - name: email\n        description: Customer email address\n        tests:\n          - not_null\n\n      - name: customer_tier\n        description: Customer value tier based on lifetime value\n        tests:\n          - accepted_values:\n              values: ['high', 'medium', 'low']\n\n      - name: lifetime_value\n        description: Total amount paid by customer\n        tests:\n          - dbt_utils.expression_is_true:\n              expression: \">= 0\"\n\n  - name: fct_orders\n    description: Order fact table with all order transactions\n    tests:\n      - dbt_utils.recency:\n          datepart: day\n          field: created_at\n          interval: 1\n    columns:\n      - name: order_id\n        tests:\n          - unique\n          - not_null\n      - name: customer_key\n        tests:\n          - not_null\n          - relationships:\n              to: ref('dim_customers')\n              field: customer_key\n```\n\n### Pattern 6: Macros and DRY Code\n\n```sql\n-- macros/cents_to_dollars.sql\n{% macro cents_to_dollars(column_name, precision=2) %}\n    round({{ column_name }} / 100.0, {{ precision }})\n{% endmacro %}\n\n-- macros/generate_schema_name.sql\n{% macro generate_schema_name(custom_schema_name, node) %}\n    {%- set default_schema = target.schema -%}\n    {%- if custom_schema_name is none -%}\n        {{ default_schema }}\n    {%- else -%}\n        {{ default_schema }}_{{ custom_schema_name }}\n    {%- endif -%}\n{% endmacro %}\n\n-- macros/limit_data_in_dev.sql\n{% macro limit_data_in_dev(column_name, days=3) %}\n    {% if target.name == 'dev' %}\n        where {{ column_name }} >= dateadd(day, -{{ days }}, current_date)\n    {% endif %}\n{% endmacro %}\n\n-- Usage in model\nselect * from {{ ref('stg_orders') }}\n{{ limit_data_in_dev('created_at') }}\n```\n\n### Pattern 7: Incremental Strategies\n\n```sql\n-- Delete+Insert (default for most warehouses)\n{{\n    config(\n        materialized='incremental',\n        unique_key='id',\n        incremental_strategy='delete+insert'\n    )\n}}\n\n-- Merge (best for late-arriving data)\n{{\n    config(\n        materialized='incremental',\n        unique_key='id',\n        incremental_strategy='merge',\n        merge_update_columns=['status', 'amount', 'updated_at']\n    )\n}}\n\n-- Insert Overwrite (partition-based)\n{{\n    config(\n        materialized='incremental',\n        incremental_strategy='insert_overwrite',\n        partition_by={\n            \"field\": \"created_date\",\n            \"data_type\": \"date\",\n            \"granularity\": \"day\"\n        }\n    )\n}}\n\nselect\n    *,\n    date(created_at) as created_date\nfrom {{ ref('stg_events') }}\n\n{% if is_incremental() %}\nwhere created_date >= dateadd(day, -3, current_date)\n{% endif %}\n```\n\n## dbt Commands\n\n```bash\n# Development\ndbt run                          # Run all models\ndbt run --select staging         # Run staging models only\ndbt run --select +fct_orders     # Run fct_orders and its upstream\ndbt run --select fct_orders+     # Run fct_orders and its downstream\ndbt run --full-refresh           # Rebuild incremental models\n\n# Testing\ndbt test                         # Run all tests\ndbt test --select stg_stripe     # Test specific models\ndbt build                        # Run + test in DAG order\n\n# Documentation\ndbt docs generate                # Generate docs\ndbt docs serve                   # Serve docs locally\n\n# Debugging\ndbt compile                      # Compile SQL without running\ndbt debug                        # Test connection\ndbt ls --select tag:critical     # List models by tag\n```\n\n## Best Practices\n\n### Do's\n- **Use staging layer** - Clean data once, use everywhere\n- **Test aggressively** - Not null, unique, relationships\n- **Document everything** - Column descriptions, model descriptions\n- **Use incremental** - For tables > 1M rows\n- **Version control** - dbt project in Git\n\n### Don'ts\n- **Don't skip staging** - Raw \u2192 mart is tech debt\n- **Don't hardcode dates** - Use `{{ var('start_date') }}`\n- **Don't repeat logic** - Extract to macros\n- **Don't test in prod** - Use dev target\n- **Don't ignore freshness** - Monitor source data\n\n## Resources\n\n- [dbt Documentation](https://docs.getdbt.com/)\n- [dbt Best Practices](https://docs.getdbt.com/guides/best-practices)\n- [dbt-utils Package](https://hub.getdbt.com/dbt-labs/dbt_utils/latest/)\n- [dbt Discourse](https://discourse.getdbt.com/)\n"
}