{
  "id": "python_development_async_python_patterns",
  "name": "async-python-patterns",
  "source": "python-development",
  "originalPath": "plugins/python-development/skills/async-python-patterns/SKILL.md",
  "activationCriteria": "Master Python asyncio, concurrent programming, and async/await patterns for high-performance applications. Use when building async APIs, concurrent systems, or I/O-bound applications requiring non-blo",
  "tier1_metadata": "async-python-patterns: Master Python asyncio, concurrent programming, and async/await patterns for high-performance applica",
  "tier2_instructions": "# Async Python Patterns\n\nComprehensive guidance for implementing asynchronous Python applications using asyncio, concurrent programming patterns, and async/await for building high-performance, non-blocking systems.\n\n## When to Use This Skill\n\n- Building async web APIs (FastAPI, aiohttp, Sanic)\n- Implementing concurrent I/O operations (database, file, network)\n- Creating web scrapers with concurrent requests\n- Developing real-time applications (WebSocket servers, chat systems)\n- Processing multiple independent tasks simultaneously\n- Building microservices with async communication\n- Optimizing I/O-bound workloads\n- Implementing async background tasks and queues\n\n## Core Concepts\n\n### 1. Event Loop\nThe event loop is the heart of asyncio, managing and scheduling asynchronous tasks.\n\n**Key characteristics:**\n- Single-threaded cooperative multitasking\n- Schedules coroutines for execution\n- Handles I/O operations without blocking\n- Manages callbacks and futures\n\n### 2. Coroutines\nFunctions defined with `async def` that can be paused and resumed.\n\n**Syntax:**\n```python\nasync def my_coroutine():\n    result = await some_async_operation()\n    return result\n```\n\n### 3. Tasks\nScheduled coroutines that run concurrently on the event loop.\n\n### 4. Futures\nLow-level objects representing eventual results of async operations.\n\n### 5. Async Context Managers\nResources that support `async with` for proper cleanup.\n\n### 6. Async Iterators\nObjects that support `async for` for iterating over async data sources.\n\n## Quick Start\n\n```python\nimport asyncio\n\nasync def main():\n    print(\"Hello\")\n    await asyncio.sleep(1)\n    print(\"World\")\n\n# Python 3.7+\nasyncio.run(main())\n```\n\n## Fundamental Patterns\n\n### Pattern 1: Basic Async/Await\n\n```python\nimport asyncio\n\nasync def fetch_data(url: str) -> dict:\n    \"\"\"Fetch data from URL asynchronously.\"\"\"\n    await asyncio.sleep(1)  # Simulate I/O\n    return {\"url\": url, \"data\": \"result\"}\n\nasync def main():\n    result = await fetch_data(\"https://api.exam",
  "tier3_resources": "ple.com\")\n    print(result)\n\nasyncio.run(main())\n```\n\n### Pattern 2: Concurrent Execution with gather()\n\n```python\nimport asyncio\nfrom typing import List\n\nasync def fetch_user(user_id: int) -> dict:\n    \"\"\"Fetch user data.\"\"\"\n    await asyncio.sleep(0.5)\n    return {\"id\": user_id, \"name\": f\"User {user_id}\"}\n\nasync def fetch_all_users(user_ids: List[int]) -> List[dict]:\n    \"\"\"Fetch multiple users concurrently.\"\"\"\n    tasks = [fetch_user(uid) for uid in user_ids]\n    results = await asyncio.gather(*tasks)\n    return results\n\nasync def main():\n    user_ids = [1, 2, 3, 4, 5]\n    users = await fetch_all_users(user_ids)\n    print(f\"Fetched {len(users)} users\")\n\nasyncio.run(main())\n```\n\n### Pattern 3: Task Creation and Management\n\n```python\nimport asyncio\n\nasync def background_task(name: str, delay: int):\n    \"\"\"Long-running background task.\"\"\"\n    print(f\"{name} started\")\n    await asyncio.sleep(delay)\n    print(f\"{name} completed\")\n    return f\"Result from {name}\"\n\nasync def main():\n    # Create tasks\n    task1 = asyncio.create_task(background_task(\"Task 1\", 2))\n    task2 = asyncio.create_task(background_task(\"Task 2\", 1))\n\n    # Do other work\n    print(\"Main: doing other work\")\n    await asyncio.sleep(0.5)\n\n    # Wait for tasks\n    result1 = await task1\n    result2 = await task2\n\n    print(f\"Results: {result1}, {result2}\")\n\nasyncio.run(main())\n```\n\n### Pattern 4: Error Handling in Async Code\n\n```python\nimport asyncio\nfrom typing import List, Optional\n\nasync def risky_operation(item_id: int) -> dict:\n    \"\"\"Operation that might fail.\"\"\"\n    await asyncio.sleep(0.1)\n    if item_id % 3 == 0:\n        raise ValueError(f\"Item {item_id} failed\")\n    return {\"id\": item_id, \"status\": \"success\"}\n\nasync def safe_operation(item_id: int) -> Optional[dict]:\n    \"\"\"Wrapper with error handling.\"\"\"\n    try:\n        return await risky_operation(item_id)\n    except ValueError as e:\n        print(f\"Error: {e}\")\n        return None\n\nasync def process_items(item_ids: List[int]):\n    \"\"\"Process multiple items with error handling.\"\"\"\n    tasks = [safe_operation(iid) for iid in item_ids]\n    results = await asyncio.gather(*tasks, return_exceptions=True)\n\n    # Filter out failures\n    successful = [r for r in results if r is not None and not isinstance(r, Exception)]\n    failed = [r for r in results if isinstance(r, Exception)]\n\n    print(f\"Success: {len(successful)}, Failed: {len(failed)}\")\n    return successful\n\nasyncio.run(process_items([1, 2, 3, 4, 5, 6]))\n```\n\n### Pattern 5: Timeout Handling\n\n```python\nimport asyncio\n\nasync def slow_operation(delay: int) -> str:\n    \"\"\"Operation that takes time.\"\"\"\n    await asyncio.sleep(delay)\n    return f\"Completed after {delay}s\"\n\nasync def with_timeout():\n    \"\"\"Execute operation with timeout.\"\"\"\n    try:\n        result = await asyncio.wait_for(slow_operation(5), timeout=2.0)\n        print(result)\n    except asyncio.TimeoutError:\n        print(\"Operation timed out\")\n\nasyncio.run(with_timeout())\n```\n\n## Advanced Patterns\n\n### Patter",
  "tokenEstimate": {
    "tier1": 15.600000000000001,
    "tier2": 336.7,
    "tier3": 2202.2000000000003
  },
  "fullDefinition": "---\nname: async-python-patterns\ndescription: Master Python asyncio, concurrent programming, and async/await patterns for high-performance applications. Use when building async APIs, concurrent systems, or I/O-bound applications requiring non-blocking operations.\n---\n\n# Async Python Patterns\n\nComprehensive guidance for implementing asynchronous Python applications using asyncio, concurrent programming patterns, and async/await for building high-performance, non-blocking systems.\n\n## When to Use This Skill\n\n- Building async web APIs (FastAPI, aiohttp, Sanic)\n- Implementing concurrent I/O operations (database, file, network)\n- Creating web scrapers with concurrent requests\n- Developing real-time applications (WebSocket servers, chat systems)\n- Processing multiple independent tasks simultaneously\n- Building microservices with async communication\n- Optimizing I/O-bound workloads\n- Implementing async background tasks and queues\n\n## Core Concepts\n\n### 1. Event Loop\nThe event loop is the heart of asyncio, managing and scheduling asynchronous tasks.\n\n**Key characteristics:**\n- Single-threaded cooperative multitasking\n- Schedules coroutines for execution\n- Handles I/O operations without blocking\n- Manages callbacks and futures\n\n### 2. Coroutines\nFunctions defined with `async def` that can be paused and resumed.\n\n**Syntax:**\n```python\nasync def my_coroutine():\n    result = await some_async_operation()\n    return result\n```\n\n### 3. Tasks\nScheduled coroutines that run concurrently on the event loop.\n\n### 4. Futures\nLow-level objects representing eventual results of async operations.\n\n### 5. Async Context Managers\nResources that support `async with` for proper cleanup.\n\n### 6. Async Iterators\nObjects that support `async for` for iterating over async data sources.\n\n## Quick Start\n\n```python\nimport asyncio\n\nasync def main():\n    print(\"Hello\")\n    await asyncio.sleep(1)\n    print(\"World\")\n\n# Python 3.7+\nasyncio.run(main())\n```\n\n## Fundamental Patterns\n\n### Pattern 1: Basic Async/Await\n\n```python\nimport asyncio\n\nasync def fetch_data(url: str) -> dict:\n    \"\"\"Fetch data from URL asynchronously.\"\"\"\n    await asyncio.sleep(1)  # Simulate I/O\n    return {\"url\": url, \"data\": \"result\"}\n\nasync def main():\n    result = await fetch_data(\"https://api.example.com\")\n    print(result)\n\nasyncio.run(main())\n```\n\n### Pattern 2: Concurrent Execution with gather()\n\n```python\nimport asyncio\nfrom typing import List\n\nasync def fetch_user(user_id: int) -> dict:\n    \"\"\"Fetch user data.\"\"\"\n    await asyncio.sleep(0.5)\n    return {\"id\": user_id, \"name\": f\"User {user_id}\"}\n\nasync def fetch_all_users(user_ids: List[int]) -> List[dict]:\n    \"\"\"Fetch multiple users concurrently.\"\"\"\n    tasks = [fetch_user(uid) for uid in user_ids]\n    results = await asyncio.gather(*tasks)\n    return results\n\nasync def main():\n    user_ids = [1, 2, 3, 4, 5]\n    users = await fetch_all_users(user_ids)\n    print(f\"Fetched {len(users)} users\")\n\nasyncio.run(main())\n```\n\n### Pattern 3: Task Creation and Management\n\n```python\nimport asyncio\n\nasync def background_task(name: str, delay: int):\n    \"\"\"Long-running background task.\"\"\"\n    print(f\"{name} started\")\n    await asyncio.sleep(delay)\n    print(f\"{name} completed\")\n    return f\"Result from {name}\"\n\nasync def main():\n    # Create tasks\n    task1 = asyncio.create_task(background_task(\"Task 1\", 2))\n    task2 = asyncio.create_task(background_task(\"Task 2\", 1))\n\n    # Do other work\n    print(\"Main: doing other work\")\n    await asyncio.sleep(0.5)\n\n    # Wait for tasks\n    result1 = await task1\n    result2 = await task2\n\n    print(f\"Results: {result1}, {result2}\")\n\nasyncio.run(main())\n```\n\n### Pattern 4: Error Handling in Async Code\n\n```python\nimport asyncio\nfrom typing import List, Optional\n\nasync def risky_operation(item_id: int) -> dict:\n    \"\"\"Operation that might fail.\"\"\"\n    await asyncio.sleep(0.1)\n    if item_id % 3 == 0:\n        raise ValueError(f\"Item {item_id} failed\")\n    return {\"id\": item_id, \"status\": \"success\"}\n\nasync def safe_operation(item_id: int) -> Optional[dict]:\n    \"\"\"Wrapper with error handling.\"\"\"\n    try:\n        return await risky_operation(item_id)\n    except ValueError as e:\n        print(f\"Error: {e}\")\n        return None\n\nasync def process_items(item_ids: List[int]):\n    \"\"\"Process multiple items with error handling.\"\"\"\n    tasks = [safe_operation(iid) for iid in item_ids]\n    results = await asyncio.gather(*tasks, return_exceptions=True)\n\n    # Filter out failures\n    successful = [r for r in results if r is not None and not isinstance(r, Exception)]\n    failed = [r for r in results if isinstance(r, Exception)]\n\n    print(f\"Success: {len(successful)}, Failed: {len(failed)}\")\n    return successful\n\nasyncio.run(process_items([1, 2, 3, 4, 5, 6]))\n```\n\n### Pattern 5: Timeout Handling\n\n```python\nimport asyncio\n\nasync def slow_operation(delay: int) -> str:\n    \"\"\"Operation that takes time.\"\"\"\n    await asyncio.sleep(delay)\n    return f\"Completed after {delay}s\"\n\nasync def with_timeout():\n    \"\"\"Execute operation with timeout.\"\"\"\n    try:\n        result = await asyncio.wait_for(slow_operation(5), timeout=2.0)\n        print(result)\n    except asyncio.TimeoutError:\n        print(\"Operation timed out\")\n\nasyncio.run(with_timeout())\n```\n\n## Advanced Patterns\n\n### Pattern 6: Async Context Managers\n\n```python\nimport asyncio\nfrom typing import Optional\n\nclass AsyncDatabaseConnection:\n    \"\"\"Async database connection context manager.\"\"\"\n\n    def __init__(self, dsn: str):\n        self.dsn = dsn\n        self.connection: Optional[object] = None\n\n    async def __aenter__(self):\n        print(\"Opening connection\")\n        await asyncio.sleep(0.1)  # Simulate connection\n        self.connection = {\"dsn\": self.dsn, \"connected\": True}\n        return self.connection\n\n    async def __aexit__(self, exc_type, exc_val, exc_tb):\n        print(\"Closing connection\")\n        await asyncio.sleep(0.1)  # Simulate cleanup\n        self.connection = None\n\nasync def query_database():\n    \"\"\"Use async context manager.\"\"\"\n    async with AsyncDatabaseConnection(\"postgresql://localhost\") as conn:\n        print(f\"Using connection: {conn}\")\n        await asyncio.sleep(0.2)  # Simulate query\n        return {\"rows\": 10}\n\nasyncio.run(query_database())\n```\n\n### Pattern 7: Async Iterators and Generators\n\n```python\nimport asyncio\nfrom typing import AsyncIterator\n\nasync def async_range(start: int, end: int, delay: float = 0.1) -> AsyncIterator[int]:\n    \"\"\"Async generator that yields numbers with delay.\"\"\"\n    for i in range(start, end):\n        await asyncio.sleep(delay)\n        yield i\n\nasync def fetch_pages(url: str, max_pages: int) -> AsyncIterator[dict]:\n    \"\"\"Fetch paginated data asynchronously.\"\"\"\n    for page in range(1, max_pages + 1):\n        await asyncio.sleep(0.2)  # Simulate API call\n        yield {\n            \"page\": page,\n            \"url\": f\"{url}?page={page}\",\n            \"data\": [f\"item_{page}_{i}\" for i in range(5)]\n        }\n\nasync def consume_async_iterator():\n    \"\"\"Consume async iterator.\"\"\"\n    async for number in async_range(1, 5):\n        print(f\"Number: {number}\")\n\n    print(\"\\nFetching pages:\")\n    async for page_data in fetch_pages(\"https://api.example.com/items\", 3):\n        print(f\"Page {page_data['page']}: {len(page_data['data'])} items\")\n\nasyncio.run(consume_async_iterator())\n```\n\n### Pattern 8: Producer-Consumer Pattern\n\n```python\nimport asyncio\nfrom asyncio import Queue\nfrom typing import Optional\n\nasync def producer(queue: Queue, producer_id: int, num_items: int):\n    \"\"\"Produce items and put them in queue.\"\"\"\n    for i in range(num_items):\n        item = f\"Item-{producer_id}-{i}\"\n        await queue.put(item)\n        print(f\"Producer {producer_id} produced: {item}\")\n        await asyncio.sleep(0.1)\n    await queue.put(None)  # Signal completion\n\nasync def consumer(queue: Queue, consumer_id: int):\n    \"\"\"Consume items from queue.\"\"\"\n    while True:\n        item = await queue.get()\n        if item is None:\n            queue.task_done()\n            break\n\n        print(f\"Consumer {consumer_id} processing: {item}\")\n        await asyncio.sleep(0.2)  # Simulate work\n        queue.task_done()\n\nasync def producer_consumer_example():\n    \"\"\"Run producer-consumer pattern.\"\"\"\n    queue = Queue(maxsize=10)\n\n    # Create tasks\n    producers = [\n        asyncio.create_task(producer(queue, i, 5))\n        for i in range(2)\n    ]\n\n    consumers = [\n        asyncio.create_task(consumer(queue, i))\n        for i in range(3)\n    ]\n\n    # Wait for producers\n    await asyncio.gather(*producers)\n\n    # Wait for queue to be empty\n    await queue.join()\n\n    # Cancel consumers\n    for c in consumers:\n        c.cancel()\n\nasyncio.run(producer_consumer_example())\n```\n\n### Pattern 9: Semaphore for Rate Limiting\n\n```python\nimport asyncio\nfrom typing import List\n\nasync def api_call(url: str, semaphore: asyncio.Semaphore) -> dict:\n    \"\"\"Make API call with rate limiting.\"\"\"\n    async with semaphore:\n        print(f\"Calling {url}\")\n        await asyncio.sleep(0.5)  # Simulate API call\n        return {\"url\": url, \"status\": 200}\n\nasync def rate_limited_requests(urls: List[str], max_concurrent: int = 5):\n    \"\"\"Make multiple requests with rate limiting.\"\"\"\n    semaphore = asyncio.Semaphore(max_concurrent)\n    tasks = [api_call(url, semaphore) for url in urls]\n    results = await asyncio.gather(*tasks)\n    return results\n\nasync def main():\n    urls = [f\"https://api.example.com/item/{i}\" for i in range(20)]\n    results = await rate_limited_requests(urls, max_concurrent=3)\n    print(f\"Completed {len(results)} requests\")\n\nasyncio.run(main())\n```\n\n### Pattern 10: Async Locks and Synchronization\n\n```python\nimport asyncio\n\nclass AsyncCounter:\n    \"\"\"Thread-safe async counter.\"\"\"\n\n    def __init__(self):\n        self.value = 0\n        self.lock = asyncio.Lock()\n\n    async def increment(self):\n        \"\"\"Safely increment counter.\"\"\"\n        async with self.lock:\n            current = self.value\n            await asyncio.sleep(0.01)  # Simulate work\n            self.value = current + 1\n\n    async def get_value(self) -> int:\n        \"\"\"Get current value.\"\"\"\n        async with self.lock:\n            return self.value\n\nasync def worker(counter: AsyncCounter, worker_id: int):\n    \"\"\"Worker that increments counter.\"\"\"\n    for _ in range(10):\n        await counter.increment()\n        print(f\"Worker {worker_id} incremented\")\n\nasync def test_counter():\n    \"\"\"Test concurrent counter.\"\"\"\n    counter = AsyncCounter()\n\n    workers = [asyncio.create_task(worker(counter, i)) for i in range(5)]\n    await asyncio.gather(*workers)\n\n    final_value = await counter.get_value()\n    print(f\"Final counter value: {final_value}\")\n\nasyncio.run(test_counter())\n```\n\n## Real-World Applications\n\n### Web Scraping with aiohttp\n\n```python\nimport asyncio\nimport aiohttp\nfrom typing import List, Dict\n\nasync def fetch_url(session: aiohttp.ClientSession, url: str) -> Dict:\n    \"\"\"Fetch single URL.\"\"\"\n    try:\n        async with session.get(url, timeout=aiohttp.ClientTimeout(total=10)) as response:\n            text = await response.text()\n            return {\n                \"url\": url,\n                \"status\": response.status,\n                \"length\": len(text)\n            }\n    except Exception as e:\n        return {\"url\": url, \"error\": str(e)}\n\nasync def scrape_urls(urls: List[str]) -> List[Dict]:\n    \"\"\"Scrape multiple URLs concurrently.\"\"\"\n    async with aiohttp.ClientSession() as session:\n        tasks = [fetch_url(session, url) for url in urls]\n        results = await asyncio.gather(*tasks)\n        return results\n\nasync def main():\n    urls = [\n        \"https://httpbin.org/delay/1\",\n        \"https://httpbin.org/delay/2\",\n        \"https://httpbin.org/status/404\",\n    ]\n\n    results = await scrape_urls(urls)\n    for result in results:\n        print(result)\n\nasyncio.run(main())\n```\n\n### Async Database Operations\n\n```python\nimport asyncio\nfrom typing import List, Optional\n\n# Simulated async database client\nclass AsyncDB:\n    \"\"\"Simulated async database.\"\"\"\n\n    async def execute(self, query: str) -> List[dict]:\n        \"\"\"Execute query.\"\"\"\n        await asyncio.sleep(0.1)\n        return [{\"id\": 1, \"name\": \"Example\"}]\n\n    async def fetch_one(self, query: str) -> Optional[dict]:\n        \"\"\"Fetch single row.\"\"\"\n        await asyncio.sleep(0.1)\n        return {\"id\": 1, \"name\": \"Example\"}\n\nasync def get_user_data(db: AsyncDB, user_id: int) -> dict:\n    \"\"\"Fetch user and related data concurrently.\"\"\"\n    user_task = db.fetch_one(f\"SELECT * FROM users WHERE id = {user_id}\")\n    orders_task = db.execute(f\"SELECT * FROM orders WHERE user_id = {user_id}\")\n    profile_task = db.fetch_one(f\"SELECT * FROM profiles WHERE user_id = {user_id}\")\n\n    user, orders, profile = await asyncio.gather(user_task, orders_task, profile_task)\n\n    return {\n        \"user\": user,\n        \"orders\": orders,\n        \"profile\": profile\n    }\n\nasync def main():\n    db = AsyncDB()\n    user_data = await get_user_data(db, 1)\n    print(user_data)\n\nasyncio.run(main())\n```\n\n### WebSocket Server\n\n```python\nimport asyncio\nfrom typing import Set\n\n# Simulated WebSocket connection\nclass WebSocket:\n    \"\"\"Simulated WebSocket.\"\"\"\n\n    def __init__(self, client_id: str):\n        self.client_id = client_id\n\n    async def send(self, message: str):\n        \"\"\"Send message.\"\"\"\n        print(f\"Sending to {self.client_id}: {message}\")\n        await asyncio.sleep(0.01)\n\n    async def recv(self) -> str:\n        \"\"\"Receive message.\"\"\"\n        await asyncio.sleep(1)\n        return f\"Message from {self.client_id}\"\n\nclass WebSocketServer:\n    \"\"\"Simple WebSocket server.\"\"\"\n\n    def __init__(self):\n        self.clients: Set[WebSocket] = set()\n\n    async def register(self, websocket: WebSocket):\n        \"\"\"Register new client.\"\"\"\n        self.clients.add(websocket)\n        print(f\"Client {websocket.client_id} connected\")\n\n    async def unregister(self, websocket: WebSocket):\n        \"\"\"Unregister client.\"\"\"\n        self.clients.remove(websocket)\n        print(f\"Client {websocket.client_id} disconnected\")\n\n    async def broadcast(self, message: str):\n        \"\"\"Broadcast message to all clients.\"\"\"\n        if self.clients:\n            tasks = [client.send(message) for client in self.clients]\n            await asyncio.gather(*tasks)\n\n    async def handle_client(self, websocket: WebSocket):\n        \"\"\"Handle individual client connection.\"\"\"\n        await self.register(websocket)\n        try:\n            async for message in self.message_iterator(websocket):\n                await self.broadcast(f\"{websocket.client_id}: {message}\")\n        finally:\n            await self.unregister(websocket)\n\n    async def message_iterator(self, websocket: WebSocket):\n        \"\"\"Iterate over messages from client.\"\"\"\n        for _ in range(3):  # Simulate 3 messages\n            yield await websocket.recv()\n```\n\n## Performance Best Practices\n\n### 1. Use Connection Pools\n\n```python\nimport asyncio\nimport aiohttp\n\nasync def with_connection_pool():\n    \"\"\"Use connection pool for efficiency.\"\"\"\n    connector = aiohttp.TCPConnector(limit=100, limit_per_host=10)\n\n    async with aiohttp.ClientSession(connector=connector) as session:\n        tasks = [session.get(f\"https://api.example.com/item/{i}\") for i in range(50)]\n        responses = await asyncio.gather(*tasks)\n        return responses\n```\n\n### 2. Batch Operations\n\n```python\nasync def batch_process(items: List[str], batch_size: int = 10):\n    \"\"\"Process items in batches.\"\"\"\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i + batch_size]\n        tasks = [process_item(item) for item in batch]\n        await asyncio.gather(*tasks)\n        print(f\"Processed batch {i // batch_size + 1}\")\n\nasync def process_item(item: str):\n    \"\"\"Process single item.\"\"\"\n    await asyncio.sleep(0.1)\n    return f\"Processed: {item}\"\n```\n\n### 3. Avoid Blocking Operations\n\n```python\nimport asyncio\nimport concurrent.futures\nfrom typing import Any\n\ndef blocking_operation(data: Any) -> Any:\n    \"\"\"CPU-intensive blocking operation.\"\"\"\n    import time\n    time.sleep(1)\n    return data * 2\n\nasync def run_in_executor(data: Any) -> Any:\n    \"\"\"Run blocking operation in thread pool.\"\"\"\n    loop = asyncio.get_event_loop()\n    with concurrent.futures.ThreadPoolExecutor() as pool:\n        result = await loop.run_in_executor(pool, blocking_operation, data)\n        return result\n\nasync def main():\n    results = await asyncio.gather(*[run_in_executor(i) for i in range(5)])\n    print(results)\n\nasyncio.run(main())\n```\n\n## Common Pitfalls\n\n### 1. Forgetting await\n\n```python\n# Wrong - returns coroutine object, doesn't execute\nresult = async_function()\n\n# Correct\nresult = await async_function()\n```\n\n### 2. Blocking the Event Loop\n\n```python\n# Wrong - blocks event loop\nimport time\nasync def bad():\n    time.sleep(1)  # Blocks!\n\n# Correct\nasync def good():\n    await asyncio.sleep(1)  # Non-blocking\n```\n\n### 3. Not Handling Cancellation\n\n```python\nasync def cancelable_task():\n    \"\"\"Task that handles cancellation.\"\"\"\n    try:\n        while True:\n            await asyncio.sleep(1)\n            print(\"Working...\")\n    except asyncio.CancelledError:\n        print(\"Task cancelled, cleaning up...\")\n        # Perform cleanup\n        raise  # Re-raise to propagate cancellation\n```\n\n### 4. Mixing Sync and Async Code\n\n```python\n# Wrong - can't call async from sync directly\ndef sync_function():\n    result = await async_function()  # SyntaxError!\n\n# Correct\ndef sync_function():\n    result = asyncio.run(async_function())\n```\n\n## Testing Async Code\n\n```python\nimport asyncio\nimport pytest\n\n# Using pytest-asyncio\n@pytest.mark.asyncio\nasync def test_async_function():\n    \"\"\"Test async function.\"\"\"\n    result = await fetch_data(\"https://api.example.com\")\n    assert result is not None\n\n@pytest.mark.asyncio\nasync def test_with_timeout():\n    \"\"\"Test with timeout.\"\"\"\n    with pytest.raises(asyncio.TimeoutError):\n        await asyncio.wait_for(slow_operation(5), timeout=1.0)\n```\n\n## Resources\n\n- **Python asyncio documentation**: https://docs.python.org/3/library/asyncio.html\n- **aiohttp**: Async HTTP client/server\n- **FastAPI**: Modern async web framework\n- **asyncpg**: Async PostgreSQL driver\n- **motor**: Async MongoDB driver\n\n## Best Practices Summary\n\n1. **Use asyncio.run()** for entry point (Python 3.7+)\n2. **Always await coroutines** to execute them\n3. **Use gather() for concurrent execution** of multiple tasks\n4. **Implement proper error handling** with try/except\n5. **Use timeouts** to prevent hanging operations\n6. **Pool connections** for better performance\n7. **Avoid blocking operations** in async code\n8. **Use semaphores** for rate limiting\n9. **Handle task cancellation** properly\n10. **Test async code** with pytest-asyncio\n"
}