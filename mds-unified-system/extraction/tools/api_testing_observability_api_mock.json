{
  "id": "api_testing_observability_api_mock",
  "name": "API Mocking Framework",
  "source": "api-testing-observability",
  "originalPath": "plugins/api-testing-observability/commands/api-mock.md",
  "command": "/api-testing-observability:api-mock",
  "parameters": {},
  "outputs": {},
  "agentsUsing": [],
  "fullDefinition": "# API Mocking Framework\n\nYou are an API mocking expert specializing in creating realistic mock services for development, testing, and demonstration purposes. Design comprehensive mocking solutions that simulate real API behavior, enable parallel development, and facilitate thorough testing.\n\n## Context\nThe user needs to create mock APIs for development, testing, or demonstration purposes. Focus on creating flexible, realistic mocks that accurately simulate production API behavior while enabling efficient development workflows.\n\n## Requirements\n$ARGUMENTS\n\n## Instructions\n\n### 1. Mock Server Setup\n\nCreate comprehensive mock server infrastructure:\n\n**Mock Server Framework**\n```python\nfrom typing import Dict, List, Any, Optional\nimport json\nimport asyncio\nfrom datetime import datetime\nfrom fastapi import FastAPI, Request, Response\nimport uvicorn\n\nclass MockAPIServer:\n    def __init__(self, config: Dict[str, Any]):\n        self.app = FastAPI(title=\"Mock API Server\")\n        self.routes = {}\n        self.middleware = []\n        self.state_manager = StateManager()\n        self.scenario_manager = ScenarioManager()\n        \n    def setup_mock_server(self):\n        \"\"\"Setup comprehensive mock server\"\"\"\n        # Configure middleware\n        self._setup_middleware()\n        \n        # Load mock definitions\n        self._load_mock_definitions()\n        \n        # Setup dynamic routes\n        self._setup_dynamic_routes()\n        \n        # Initialize scenarios\n        self._initialize_scenarios()\n        \n        return self.app\n    \n    def _setup_middleware(self):\n        \"\"\"Configure server middleware\"\"\"\n        @self.app.middleware(\"http\")\n        async def add_mock_headers(request: Request, call_next):\n            response = await call_next(request)\n            response.headers[\"X-Mock-Server\"] = \"true\"\n            response.headers[\"X-Mock-Scenario\"] = self.scenario_manager.current_scenario\n            return response\n        \n        @self.app.middleware(\"http\")\n        async def simulate_latency(request: Request, call_next):\n            # Simulate network latency\n            latency = self._calculate_latency(request.url.path)\n            await asyncio.sleep(latency / 1000)  # Convert to seconds\n            response = await call_next(request)\n            return response\n        \n        @self.app.middleware(\"http\")\n        async def track_requests(request: Request, call_next):\n            # Track request for verification\n            self.state_manager.track_request({\n                'method': request.method,\n                'path': str(request.url.path),\n                'headers': dict(request.headers),\n                'timestamp': datetime.now()\n            })\n            response = await call_next(request)\n            return response\n    \n    def _setup_dynamic_routes(self):\n        \"\"\"Setup dynamic route handling\"\"\"\n        @self.app.api_route(\"/{path:path}\", methods=[\"GET\", \"POST\", \"PUT\", \"DELETE\", \"PATCH\"])\n        async def handle_mock_request(path: str, request: Request):\n            # Find matching mock\n            mock = self._find_matching_mock(request.method, path, request)\n            \n            if not mock:\n                return Response(\n                    content=json.dumps({\"error\": \"No mock found for this endpoint\"}),\n                    status_code=404,\n                    media_type=\"application/json\"\n                )\n            \n            # Process mock response\n            response_data = await self._process_mock_response(mock, request)\n            \n            return Response(\n                content=json.dumps(response_data['body']),\n                status_code=response_data['status'],\n                headers=response_data['headers'],\n                media_type=\"application/json\"\n            )\n    \n    async def _process_mock_response(self, mock: Dict[str, Any], request: Request):\n        \"\"\"Process and generate mock response\"\"\"\n        # Check for conditional responses\n        if mock.get('conditions'):\n            for condition in mock['conditions']:\n                if self._evaluate_condition(condition, request):\n                    return await self._generate_response(condition['response'], request)\n        \n        # Use default response\n        return await self._generate_response(mock['response'], request)\n    \n    def _generate_response(self, response_template: Dict[str, Any], request: Request):\n        \"\"\"Generate response from template\"\"\"\n        response = {\n            'status': response_template.get('status', 200),\n            'headers': response_template.get('headers', {}),\n            'body': self._process_response_body(response_template['body'], request)\n        }\n        \n        # Apply response transformations\n        if response_template.get('transformations'):\n            response = self._apply_transformations(response, response_template['transformations'])\n        \n        return response\n```\n\n### 2. Request/Response Stubbing\n\nImplement flexible stubbing system:\n\n**Stubbing Engine**\n```python\nclass StubbingEngine:\n    def __init__(self):\n        self.stubs = {}\n        self.matchers = self._initialize_matchers()\n        \n    def create_stub(self, method: str, path: str, **kwargs):\n        \"\"\"Create a new stub\"\"\"\n        stub_id = self._generate_stub_id()\n        \n        stub = {\n            'id': stub_id,\n            'method': method,\n            'path': path,\n            'matchers': self._build_matchers(kwargs),\n            'response': kwargs.get('response', {}),\n            'priority': kwargs.get('priority', 0),\n            'times': kwargs.get('times', -1),  # -1 for unlimited\n            'delay': kwargs.get('delay', 0),\n            'scenario': kwargs.get('scenario', 'default')\n        }\n        \n        self.stubs[stub_id] = stub\n        return stub_id\n    \n    def _build_matchers(self, kwargs):\n        \"\"\"Build request matchers\"\"\"\n        matchers = []\n        \n        # Path parameter matching\n        if 'path_params' in kwargs:\n            matchers.append({\n                'type': 'path_params',\n                'params': kwargs['path_params']\n            })\n        \n        # Query parameter matching\n        if 'query_params' in kwargs:\n            matchers.append({\n                'type': 'query_params',\n                'params': kwargs['query_params']\n            })\n        \n        # Header matching\n        if 'headers' in kwargs:\n            matchers.append({\n                'type': 'headers',\n                'headers': kwargs['headers']\n            })\n        \n        # Body matching\n        if 'body' in kwargs:\n            matchers.append({\n                'type': 'body',\n                'body': kwargs['body'],\n                'match_type': kwargs.get('body_match_type', 'exact')\n            })\n        \n        return matchers\n    \n    def match_request(self, request: Dict[str, Any]):\n        \"\"\"Find matching stub for request\"\"\"\n        candidates = []\n        \n        for stub in self.stubs.values():\n            if self._matches_stub(request, stub):\n                candidates.append(stub)\n        \n        # Sort by priority and return best match\n        if candidates:\n            return sorted(candidates, key=lambda x: x['priority'], reverse=True)[0]\n        \n        return None\n    \n    def _matches_stub(self, request: Dict[str, Any], stub: Dict[str, Any]):\n        \"\"\"Check if request matches stub\"\"\"\n        # Check method\n        if request['method'] != stub['method']:\n            return False\n        \n        # Check path\n        if not self._matches_path(request['path'], stub['path']):\n            return False\n        \n        # Check all matchers\n        for matcher in stub['matchers']:\n            if not self._evaluate_matcher(request, matcher):\n                return False\n        \n        # Check if stub is still valid\n        if stub['times'] == 0:\n            return False\n        \n        return True\n    \n    def create_dynamic_stub(self):\n        \"\"\"Create dynamic stub with callbacks\"\"\"\n        return '''\nclass DynamicStub:\n    def __init__(self, path_pattern: str):\n        self.path_pattern = path_pattern\n        self.response_generator = None\n        self.state_modifier = None\n        \n    def with_response_generator(self, generator):\n        \"\"\"Set dynamic response generator\"\"\"\n        self.response_generator = generator\n        return self\n    \n    def with_state_modifier(self, modifier):\n        \"\"\"Set state modification callback\"\"\"\n        self.state_modifier = modifier\n        return self\n    \n    async def process_request(self, request: Request, state: Dict[str, Any]):\n        \"\"\"Process request dynamically\"\"\"\n        # Extract request data\n        request_data = {\n            'method': request.method,\n            'path': request.url.path,\n            'headers': dict(request.headers),\n            'query_params': dict(request.query_params),\n            'body': await request.json() if request.method in ['POST', 'PUT'] else None\n        }\n        \n        # Modify state if needed\n        if self.state_modifier:\n            state = self.state_modifier(state, request_data)\n        \n        # Generate response\n        if self.response_generator:\n            response = self.response_generator(request_data, state)\n        else:\n            response = {'status': 200, 'body': {}}\n        \n        return response, state\n\n# Usage example\ndynamic_stub = DynamicStub('/api/users/{user_id}')\ndynamic_stub.with_response_generator(lambda req, state: {\n    'status': 200,\n    'body': {\n        'id': req['path_params']['user_id'],\n        'name': state.get('users', {}).get(req['path_params']['user_id'], 'Unknown'),\n        'request_count': state.get('request_count', 0)\n    }\n}).with_state_modifier(lambda state, req: {\n    **state,\n    'request_count': state.get('request_count', 0) + 1\n})\n'''\n```\n\n### 3. Dynamic Data Generation\n\nGenerate realistic mock data:\n\n**Mock Data Generator**\n```python\nfrom faker import Faker\nimport random\nfrom datetime import datetime, timedelta\n\nclass MockDataGenerator:\n    def __init__(self):\n        self.faker = Faker()\n        self.templates = {}\n        self.generators = self._init_generators()\n        \n    def generate_data(self, schema: Dict[str, Any]):\n        \"\"\"Generate data based on schema\"\"\"\n        if isinstance(schema, dict):\n            if '$ref' in schema:\n                # Reference to another schema\n                return self.generate_data(self.resolve_ref(schema['$ref']))\n            \n            result = {}\n            for key, value in schema.items():\n                if key.startswith('$'):\n                    continue\n                result[key] = self._generate_field(value)\n            return result\n        \n        elif isinstance(schema, list):\n            # Generate array\n            count = random.randint(1, 10)\n            return [self.generate_data(schema[0]) for _ in range(count)]\n        \n        else:\n            return schema\n    \n    def _generate_field(self, field_schema: Dict[str, Any]):\n        \"\"\"Generate field value based on schema\"\"\"\n        field_type = field_schema.get('type', 'string')\n        \n        # Check for custom generator\n        if 'generator' in field_schema:\n            return self._use_custom_generator(field_schema['generator'])\n        \n        # Check for enum\n        if 'enum' in field_schema:\n            return random.choice(field_schema['enum'])\n        \n        # Generate based on type\n        generators = {\n            'string': self._generate_string,\n            'number': self._generate_number,\n            'integer': self._generate_integer,\n            'boolean': self._generate_boolean,\n            'array': self._generate_array,\n            'object': lambda s: self.generate_data(s)\n        }\n        \n        generator = generators.get(field_type, self._generate_string)\n        return generator(field_schema)\n    \n    def _generate_string(self, schema: Dict[str, Any]):\n        \"\"\"Generate string value\"\"\"\n        # Check for format\n        format_type = schema.get('format', '')\n        \n        format_generators = {\n            'email': self.faker.email,\n            'name': self.faker.name,\n            'first_name': self.faker.first_name,\n            'last_name': self.faker.last_name,\n            'phone': self.faker.phone_number,\n            'address': self.faker.address,\n            'url': self.faker.url,\n            'uuid': self.faker.uuid4,\n            'date': lambda: self.faker.date().isoformat(),\n            'datetime': lambda: self.faker.date_time().isoformat(),\n            'password': lambda: self.faker.password()\n        }\n        \n        if format_type in format_generators:\n            return format_generators[format_type]()\n        \n        # Check for pattern\n        if 'pattern' in schema:\n            return self._generate_from_pattern(schema['pattern'])\n        \n        # Default string generation\n        min_length = schema.get('minLength', 5)\n        max_length = schema.get('maxLength', 20)\n        return self.faker.text(max_nb_chars=random.randint(min_length, max_length))\n    \n    def create_data_templates(self):\n        \"\"\"Create reusable data templates\"\"\"\n        return {\n            'user': {\n                'id': {'type': 'string', 'format': 'uuid'},\n                'username': {'type': 'string', 'generator': 'username'},\n                'email': {'type': 'string', 'format': 'email'},\n                'profile': {\n                    'type': 'object',\n                    'properties': {\n                        'firstName': {'type': 'string', 'format': 'first_name'},\n                        'lastName': {'type': 'string', 'format': 'last_name'},\n                        'avatar': {'type': 'string', 'format': 'url'},\n                        'bio': {'type': 'string', 'maxLength': 200}\n                    }\n                },\n                'createdAt': {'type': 'string', 'format': 'datetime'},\n                'status': {'type': 'string', 'enum': ['active', 'inactive', 'suspended']}\n            },\n            'product': {\n                'id': {'type': 'string', 'format': 'uuid'},\n                'name': {'type': 'string', 'generator': 'product_name'},\n                'description': {'type': 'string', 'maxLength': 500},\n                'price': {'type': 'number', 'minimum': 0.01, 'maximum': 9999.99},\n                'category': {'type': 'string', 'enum': ['electronics', 'clothing', 'food', 'books']},\n                'inStock': {'type': 'boolean'},\n                'rating': {'type': 'number', 'minimum': 0, 'maximum': 5}\n            }\n        }\n    \n    def generate_relational_data(self):\n        \"\"\"Generate data with relationships\"\"\"\n        return '''\nclass RelationalDataGenerator:\n    def generate_related_entities(self, schema: Dict[str, Any], count: int):\n        \"\"\"Generate related entities maintaining referential integrity\"\"\"\n        entities = {}\n        \n        # First pass: generate primary entities\n        for entity_name, entity_schema in schema['entities'].items():\n            entities[entity_name] = []\n            for i in range(count):\n                entity = self.generate_entity(entity_schema)\n                entity['id'] = f\"{entity_name}_{i}\"\n                entities[entity_name].append(entity)\n        \n        # Second pass: establish relationships\n        for relationship in schema.get('relationships', []):\n            self.establish_relationship(entities, relationship)\n        \n        return entities\n    \n    def establish_relationship(self, entities: Dict[str, List], relationship: Dict):\n        \"\"\"Establish relationships between entities\"\"\"\n        source = relationship['source']\n        target = relationship['target']\n        rel_type = relationship['type']\n        \n        if rel_type == 'one-to-many':\n            for source_entity in entities[source['entity']]:\n                # Select random targets\n                num_targets = random.randint(1, 5)\n                target_refs = random.sample(\n                    entities[target['entity']], \n                    min(num_targets, len(entities[target['entity']]))\n                )\n                source_entity[source['field']] = [t['id'] for t in target_refs]\n        \n        elif rel_type == 'many-to-one':\n            for target_entity in entities[target['entity']]:\n                # Select one source\n                source_ref = random.choice(entities[source['entity']])\n                target_entity[target['field']] = source_ref['id']\n'''\n```\n\n### 4. Mock Scenarios\n\nImplement scenario-based mocking:\n\n**Scenario Manager**\n```python\nclass ScenarioManager:\n    def __init__(self):\n        self.scenarios = {}\n        self.current_scenario = 'default'\n        self.scenario_states = {}\n        \n    def define_scenario(self, name: str, definition: Dict[str, Any]):\n        \"\"\"Define a mock scenario\"\"\"\n        self.scenarios[name] = {\n            'name': name,\n            'description': definition.get('description', ''),\n            'initial_state': definition.get('initial_state', {}),\n            'stubs': definition.get('stubs', []),\n            'sequences': definition.get('sequences', []),\n            'conditions': definition.get('conditions', [])\n        }\n    \n    def create_test_scenarios(self):\n        \"\"\"Create common test scenarios\"\"\"\n        return {\n            'happy_path': {\n                'description': 'All operations succeed',\n                'stubs': [\n                    {\n                        'path': '/api/auth/login',\n                        'response': {\n                            'status': 200,\n                            'body': {\n                                'token': 'valid_token',\n                                'user': {'id': '123', 'name': 'Test User'}\n                            }\n                        }\n                    },\n                    {\n                        'path': '/api/users/{id}',\n                        'response': {\n                            'status': 200,\n                            'body': {\n                                'id': '{id}',\n                                'name': 'Test User',\n                                'email': 'test@example.com'\n                            }\n                        }\n                    }\n                ]\n            },\n            'error_scenario': {\n                'description': 'Various error conditions',\n                'sequences': [\n                    {\n                        'name': 'rate_limiting',\n                        'steps': [\n                            {'repeat': 5, 'response': {'status': 200}},\n                            {'repeat': 10, 'response': {'status': 429, 'body': {'error': 'Rate limit exceeded'}}}\n                        ]\n                    }\n                ],\n                'stubs': [\n                    {\n                        'path': '/api/auth/login',\n                        'conditions': [\n                            {\n                                'match': {'body': {'username': 'locked_user'}},\n                                'response': {'status': 423, 'body': {'error': 'Account locked'}}\n                            }\n                        ]\n                    }\n                ]\n            },\n            'degraded_performance': {\n                'description': 'Slow responses and timeouts',\n                'stubs': [\n                    {\n                        'path': '/api/*',\n                        'delay': 5000,  # 5 second delay\n                        'response': {'status': 200}\n                    }\n                ]\n            }\n        }\n    \n    def execute_scenario_sequence(self):\n        \"\"\"Execute scenario sequences\"\"\"\n        return '''\nclass SequenceExecutor:\n    def __init__(self):\n        self.sequence_states = {}\n        \n    def get_sequence_response(self, sequence_name: str, request: Dict):\n        \"\"\"Get response based on sequence state\"\"\"\n        if sequence_name not in self.sequence_states:\n            self.sequence_states[sequence_name] = {'step': 0, 'count': 0}\n        \n        state = self.sequence_states[sequence_name]\n        sequence = self.get_sequence_definition(sequence_name)\n        \n        # Get current step\n        current_step = sequence['steps'][state['step']]\n        \n        # Check if we should advance to next step\n        state['count'] += 1\n        if state['count'] >= current_step.get('repeat', 1):\n            state['step'] = (state['step'] + 1) % len(sequence['steps'])\n            state['count'] = 0\n        \n        return current_step['response']\n    \n    def create_stateful_scenario(self):\n        \"\"\"Create scenario with stateful behavior\"\"\"\n        return {\n            'shopping_cart': {\n                'initial_state': {\n                    'cart': {},\n                    'total': 0\n                },\n                'stubs': [\n                    {\n                        'method': 'POST',\n                        'path': '/api/cart/items',\n                        'handler': 'add_to_cart',\n                        'modifies_state': True\n                    },\n                    {\n                        'method': 'GET',\n                        'path': '/api/cart',\n                        'handler': 'get_cart',\n                        'uses_state': True\n                    }\n                ],\n                'handlers': {\n                    'add_to_cart': lambda state, request: {\n                        'state': {\n                            **state,\n                            'cart': {\n                                **state['cart'],\n                                request['body']['product_id']: request['body']['quantity']\n                            },\n                            'total': state['total'] + request['body']['price']\n                        },\n                        'response': {\n                            'status': 201,\n                            'body': {'message': 'Item added to cart'}\n                        }\n                    },\n                    'get_cart': lambda state, request: {\n                        'response': {\n                            'status': 200,\n                            'body': {\n                                'items': state['cart'],\n                                'total': state['total']\n                            }\n                        }\n                    }\n                }\n            }\n        }\n'''\n```\n\n### 5. Contract Testing\n\nImplement contract-based mocking:\n\n**Contract Testing Framework**\n```python\nclass ContractMockServer:\n    def __init__(self):\n        self.contracts = {}\n        self.validators = self._init_validators()\n        \n    def load_contract(self, contract_path: str):\n        \"\"\"Load API contract (OpenAPI, AsyncAPI, etc.)\"\"\"\n        with open(contract_path, 'r') as f:\n            contract = yaml.safe_load(f)\n        \n        # Parse contract\n        self.contracts[contract['info']['title']] = {\n            'spec': contract,\n            'endpoints': self._parse_endpoints(contract),\n            'schemas': self._parse_schemas(contract)\n        }\n    \n    def generate_mocks_from_contract(self, contract_name: str):\n        \"\"\"Generate mocks from contract specification\"\"\"\n        contract = self.contracts[contract_name]\n        mocks = []\n        \n        for path, methods in contract['endpoints'].items():\n            for method, spec in methods.items():\n                mock = self._create_mock_from_spec(path, method, spec)\n                mocks.append(mock)\n        \n        return mocks\n    \n    def _create_mock_from_spec(self, path: str, method: str, spec: Dict):\n        \"\"\"Create mock from endpoint specification\"\"\"\n        mock = {\n            'method': method.upper(),\n            'path': self._convert_path_to_pattern(path),\n            'responses': {}\n        }\n        \n        # Generate responses for each status code\n        for status_code, response_spec in spec.get('responses', {}).items():\n            mock['responses'][status_code] = {\n                'status': int(status_code),\n                'headers': self._get_response_headers(response_spec),\n                'body': self._generate_response_body(response_spec)\n            }\n        \n        # Add request validation\n        if 'requestBody' in spec:\n            mock['request_validation'] = self._create_request_validator(spec['requestBody'])\n        \n        return mock\n    \n    def validate_against_contract(self):\n        \"\"\"Validate mock responses against contract\"\"\"\n        return '''\nclass ContractValidator:\n    def validate_response(self, contract_spec, actual_response):\n        \"\"\"Validate response against contract\"\"\"\n        validation_results = {\n            'valid': True,\n            'errors': []\n        }\n        \n        # Find response spec for status code\n        response_spec = contract_spec['responses'].get(\n            str(actual_response['status']),\n            contract_spec['responses'].get('default')\n        )\n        \n        if not response_spec:\n            validation_results['errors'].append({\n                'type': 'unexpected_status',\n                'message': f\"Status {actual_response['status']} not defined in contract\"\n            })\n            validation_results['valid'] = False\n            return validation_results\n        \n        # Validate headers\n        if 'headers' in response_spec:\n            header_errors = self.validate_headers(\n                response_spec['headers'],\n                actual_response['headers']\n            )\n            validation_results['errors'].extend(header_errors)\n        \n        # Validate body schema\n        if 'content' in response_spec:\n            body_errors = self.validate_body(\n                response_spec['content'],\n                actual_response['body']\n            )\n            validation_results['errors'].extend(body_errors)\n        \n        validation_results['valid'] = len(validation_results['errors']) == 0\n        return validation_results\n    \n    def validate_body(self, content_spec, actual_body):\n        \"\"\"Validate response body against schema\"\"\"\n        errors = []\n        \n        # Get schema for content type\n        schema = content_spec.get('application/json', {}).get('schema')\n        if not schema:\n            return errors\n        \n        # Validate against JSON schema\n        try:\n            validate(instance=actual_body, schema=schema)\n        except ValidationError as e:\n            errors.append({\n                'type': 'schema_validation',\n                'path': e.json_path,\n                'message': e.message\n            })\n        \n        return errors\n'''\n```\n\n### 6. Performance Testing\n\nCreate performance testing mocks:\n\n**Performance Mock Server**\n```python\nclass PerformanceMockServer:\n    def __init__(self):\n        self.performance_profiles = {}\n        self.metrics_collector = MetricsCollector()\n        \n    def create_performance_profile(self, name: str, config: Dict):\n        \"\"\"Create performance testing profile\"\"\"\n        self.performance_profiles[name] = {\n            'latency': config.get('latency', {'min': 10, 'max': 100}),\n            'throughput': config.get('throughput', 1000),  # requests per second\n            'error_rate': config.get('error_rate', 0.01),  # 1% errors\n            'response_size': config.get('response_size', {'min': 100, 'max': 10000})\n        }\n    \n    async def simulate_performance(self, profile_name: str, request: Request):\n        \"\"\"Simulate performance characteristics\"\"\"\n        profile = self.performance_profiles[profile_name]\n        \n        # Simulate latency\n        latency = random.uniform(profile['latency']['min'], profile['latency']['max'])\n        await asyncio.sleep(latency / 1000)\n        \n        # Simulate errors\n        if random.random() < profile['error_rate']:\n            return self._generate_error_response()\n        \n        # Generate response with specified size\n        response_size = random.randint(\n            profile['response_size']['min'],\n            profile['response_size']['max']\n        )\n        \n        response_data = self._generate_data_of_size(response_size)\n        \n        # Track metrics\n        self.metrics_collector.record({\n            'latency': latency,\n            'response_size': response_size,\n            'timestamp': datetime.now()\n        })\n        \n        return response_data\n    \n    def create_load_test_scenarios(self):\n        \"\"\"Create load testing scenarios\"\"\"\n        return {\n            'gradual_load': {\n                'description': 'Gradually increase load',\n                'stages': [\n                    {'duration': 60, 'target_rps': 100},\n                    {'duration': 120, 'target_rps': 500},\n                    {'duration': 180, 'target_rps': 1000},\n                    {'duration': 60, 'target_rps': 100}\n                ]\n            },\n            'spike_test': {\n                'description': 'Sudden spike in traffic',\n                'stages': [\n                    {'duration': 60, 'target_rps': 100},\n                    {'duration': 10, 'target_rps': 5000},\n                    {'duration': 60, 'target_rps': 100}\n                ]\n            },\n            'stress_test': {\n                'description': 'Find breaking point',\n                'stages': [\n                    {'duration': 60, 'target_rps': 100},\n                    {'duration': 60, 'target_rps': 500},\n                    {'duration': 60, 'target_rps': 1000},\n                    {'duration': 60, 'target_rps': 2000},\n                    {'duration': 60, 'target_rps': 5000},\n                    {'duration': 60, 'target_rps': 10000}\n                ]\n            }\n        }\n    \n    def implement_throttling(self):\n        \"\"\"Implement request throttling\"\"\"\n        return '''\nclass ThrottlingMiddleware:\n    def __init__(self, max_rps: int):\n        self.max_rps = max_rps\n        self.request_times = deque()\n        \n    async def __call__(self, request: Request, call_next):\n        current_time = time.time()\n        \n        # Remove old requests\n        while self.request_times and self.request_times[0] < current_time - 1:\n            self.request_times.popleft()\n        \n        # Check if we're over limit\n        if len(self.request_times) >= self.max_rps:\n            return Response(\n                content=json.dumps({\n                    'error': 'Rate limit exceeded',\n                    'retry_after': 1\n                }),\n                status_code=429,\n                headers={'Retry-After': '1'}\n            )\n        \n        # Record this request\n        self.request_times.append(current_time)\n        \n        # Process request\n        response = await call_next(request)\n        return response\n'''\n```\n\n### 7. Mock Data Management\n\nManage mock data effectively:\n\n**Mock Data Store**\n```python\nclass MockDataStore:\n    def __init__(self):\n        self.collections = {}\n        self.indexes = {}\n        \n    def create_collection(self, name: str, schema: Dict = None):\n        \"\"\"Create a new data collection\"\"\"\n        self.collections[name] = {\n            'data': {},\n            'schema': schema,\n            'counter': 0\n        }\n        \n        # Create default index on 'id'\n        self.create_index(name, 'id')\n    \n    def insert(self, collection: str, data: Dict):\n        \"\"\"Insert data into collection\"\"\"\n        collection_data = self.collections[collection]\n        \n        # Validate against schema if exists\n        if collection_data['schema']:\n            self._validate_data(data, collection_data['schema'])\n        \n        # Generate ID if not provided\n        if 'id' not in data:\n            collection_data['counter'] += 1\n            data['id'] = str(collection_data['counter'])\n        \n        # Store data\n        collection_data['data'][data['id']] = data\n        \n        # Update indexes\n        self._update_indexes(collection, data)\n        \n        return data['id']\n    \n    def query(self, collection: str, filters: Dict = None):\n        \"\"\"Query collection with filters\"\"\"\n        collection_data = self.collections[collection]['data']\n        \n        if not filters:\n            return list(collection_data.values())\n        \n        # Use indexes if available\n        if self._can_use_index(collection, filters):\n            return self._query_with_index(collection, filters)\n        \n        # Full scan\n        results = []\n        for item in collection_data.values():\n            if self._matches_filters(item, filters):\n                results.append(item)\n        \n        return results\n    \n    def create_relationships(self):\n        \"\"\"Define relationships between collections\"\"\"\n        return '''\nclass RelationshipManager:\n    def __init__(self, data_store: MockDataStore):\n        self.store = data_store\n        self.relationships = {}\n        \n    def define_relationship(self, \n                          source_collection: str,\n                          target_collection: str,\n                          relationship_type: str,\n                          foreign_key: str):\n        \"\"\"Define relationship between collections\"\"\"\n        self.relationships[f\"{source_collection}->{target_collection}\"] = {\n            'type': relationship_type,\n            'source': source_collection,\n            'target': target_collection,\n            'foreign_key': foreign_key\n        }\n    \n    def populate_related_data(self, entity: Dict, collection: str, depth: int = 1):\n        \"\"\"Populate related data for entity\"\"\"\n        if depth <= 0:\n            return entity\n        \n        # Find relationships for this collection\n        for rel_key, rel in self.relationships.items():\n            if rel['source'] == collection:\n                # Get related data\n                foreign_id = entity.get(rel['foreign_key'])\n                if foreign_id:\n                    related = self.store.get(rel['target'], foreign_id)\n                    if related:\n                        # Recursively populate\n                        related = self.populate_related_data(\n                            related, \n                            rel['target'], \n                            depth - 1\n                        )\n                        entity[rel['target']] = related\n        \n        return entity\n    \n    def cascade_operations(self, operation: str, collection: str, entity_id: str):\n        \"\"\"Handle cascade operations\"\"\"\n        if operation == 'delete':\n            # Find dependent relationships\n            for rel in self.relationships.values():\n                if rel['target'] == collection:\n                    # Delete dependent entities\n                    dependents = self.store.query(\n                        rel['source'],\n                        {rel['foreign_key']: entity_id}\n                    )\n                    for dep in dependents:\n                        self.store.delete(rel['source'], dep['id'])\n'''\n```\n\n### 8. Testing Framework Integration\n\nIntegrate with popular testing frameworks:\n\n**Testing Integration**\n```python\nclass TestingFrameworkIntegration:\n    def create_jest_integration(self):\n        \"\"\"Jest testing integration\"\"\"\n        return '''\n// jest.mock.config.js\nimport { MockServer } from './mockServer';\n\nconst mockServer = new MockServer();\n\nbeforeAll(async () => {\n    await mockServer.start({ port: 3001 });\n    \n    // Load mock definitions\n    await mockServer.loadMocks('./mocks/*.json');\n    \n    // Set default scenario\n    await mockServer.setScenario('test');\n});\n\nafterAll(async () => {\n    await mockServer.stop();\n});\n\nbeforeEach(async () => {\n    // Reset mock state\n    await mockServer.reset();\n});\n\n// Test helper functions\nexport const setupMock = async (stub) => {\n    return await mockServer.addStub(stub);\n};\n\nexport const verifyRequests = async (matcher) => {\n    const requests = await mockServer.getRequests(matcher);\n    return requests;\n};\n\n// Example test\ndescribe('User API', () => {\n    it('should fetch user details', async () => {\n        // Setup mock\n        await setupMock({\n            method: 'GET',\n            path: '/api/users/123',\n            response: {\n                status: 200,\n                body: { id: '123', name: 'Test User' }\n            }\n        });\n        \n        // Make request\n        const response = await fetch('http://localhost:3001/api/users/123');\n        const user = await response.json();\n        \n        // Verify\n        expect(user.name).toBe('Test User');\n        \n        // Verify mock was called\n        const requests = await verifyRequests({ path: '/api/users/123' });\n        expect(requests).toHaveLength(1);\n    });\n});\n'''\n    \n    def create_pytest_integration(self):\n        \"\"\"Pytest integration\"\"\"\n        return '''\n# conftest.py\nimport pytest\nfrom mock_server import MockServer\nimport asyncio\n\n@pytest.fixture(scope=\"session\")\ndef event_loop():\n    loop = asyncio.get_event_loop_policy().new_event_loop()\n    yield loop\n    loop.close()\n\n@pytest.fixture(scope=\"session\")\nasync def mock_server(event_loop):\n    server = MockServer()\n    await server.start(port=3001)\n    yield server\n    await server.stop()\n\n@pytest.fixture(autouse=True)\nasync def reset_mocks(mock_server):\n    await mock_server.reset()\n    yield\n    # Verify no unexpected calls\n    unmatched = await mock_server.get_unmatched_requests()\n    assert len(unmatched) == 0, f\"Unmatched requests: {unmatched}\"\n\n# Test utilities\nclass MockBuilder:\n    def __init__(self, mock_server):\n        self.server = mock_server\n        self.stubs = []\n    \n    def when(self, method, path):\n        self.current_stub = {\n            'method': method,\n            'path': path\n        }\n        return self\n    \n    def with_body(self, body):\n        self.current_stub['body'] = body\n        return self\n    \n    def then_return(self, status, body=None, headers=None):\n        self.current_stub['response'] = {\n            'status': status,\n            'body': body,\n            'headers': headers or {}\n        }\n        self.stubs.append(self.current_stub)\n        return self\n    \n    async def setup(self):\n        for stub in self.stubs:\n            await self.server.add_stub(stub)\n\n# Example test\n@pytest.mark.asyncio\nasync def test_user_creation(mock_server):\n    # Setup mocks\n    mock = MockBuilder(mock_server)\n    mock.when('POST', '/api/users') \\\n        .with_body({'name': 'New User'}) \\\n        .then_return(201, {'id': '456', 'name': 'New User'})\n    \n    await mock.setup()\n    \n    # Test code here\n    response = await create_user({'name': 'New User'})\n    assert response['id'] == '456'\n'''\n```\n\n### 9. Mock Server Deployment\n\nDeploy mock servers:\n\n**Deployment Configuration**\n```yaml\n# docker-compose.yml for mock services\nversion: '3.8'\n\nservices:\n  mock-api:\n    build:\n      context: .\n      dockerfile: Dockerfile.mock\n    ports:\n      - \"3001:3001\"\n    environment:\n      - MOCK_SCENARIO=production\n      - MOCK_DATA_PATH=/data/mocks\n    volumes:\n      - ./mocks:/data/mocks\n      - ./scenarios:/data/scenarios\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:3001/health\"]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n\n  mock-admin:\n    build:\n      context: .\n      dockerfile: Dockerfile.admin\n    ports:\n      - \"3002:3002\"\n    environment:\n      - MOCK_SERVER_URL=http://mock-api:3001\n    depends_on:\n      - mock-api\n\n# Kubernetes deployment\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mock-server\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: mock-server\n  template:\n    metadata:\n      labels:\n        app: mock-server\n    spec:\n      containers:\n      - name: mock-server\n        image: mock-server:latest\n        ports:\n        - containerPort: 3001\n        env:\n        - name: MOCK_SCENARIO\n          valueFrom:\n            configMapKeyRef:\n              name: mock-config\n              key: scenario\n        volumeMounts:\n        - name: mock-definitions\n          mountPath: /data/mocks\n      volumes:\n      - name: mock-definitions\n        configMap:\n          name: mock-definitions\n```\n\n### 10. Mock Documentation\n\nGenerate mock API documentation:\n\n**Documentation Generator**\n```python\nclass MockDocumentationGenerator:\n    def generate_documentation(self, mock_server):\n        \"\"\"Generate comprehensive mock documentation\"\"\"\n        return f\"\"\"\n# Mock API Documentation\n\n## Overview\n{self._generate_overview(mock_server)}\n\n## Available Endpoints\n{self._generate_endpoints_doc(mock_server)}\n\n## Scenarios\n{self._generate_scenarios_doc(mock_server)}\n\n## Data Models\n{self._generate_models_doc(mock_server)}\n\n## Usage Examples\n{self._generate_examples(mock_server)}\n\n## Configuration\n{self._generate_config_doc(mock_server)}\n\"\"\"\n    \n    def _generate_endpoints_doc(self, mock_server):\n        \"\"\"Generate endpoint documentation\"\"\"\n        doc = \"\"\n        for endpoint in mock_server.get_endpoints():\n            doc += f\"\"\"\n### {endpoint['method']} {endpoint['path']}\n\n**Description**: {endpoint.get('description', 'No description')}\n\n**Request**:\n```json\n{json.dumps(endpoint.get('request_example', {}), indent=2)}\n```\n\n**Response**:\n```json\n{json.dumps(endpoint.get('response_example', {}), indent=2)}\n```\n\n**Scenarios**:\n{self._format_endpoint_scenarios(endpoint)}\n\"\"\"\n        return doc\n    \n    def create_interactive_docs(self):\n        \"\"\"Create interactive API documentation\"\"\"\n        return '''\n<!DOCTYPE html>\n<html>\n<head>\n    <title>Mock API Interactive Documentation</title>\n    <script src=\"https://unpkg.com/swagger-ui-dist/swagger-ui-bundle.js\"></script>\n    <link rel=\"stylesheet\" href=\"https://unpkg.com/swagger-ui-dist/swagger-ui.css\">\n</head>\n<body>\n    <div id=\"swagger-ui\"></div>\n    <script>\n        window.onload = function() {\n            const ui = SwaggerUIBundle({\n                url: \"/api/mock/openapi.json\",\n                dom_id: '#swagger-ui',\n                presets: [\n                    SwaggerUIBundle.presets.apis,\n                    SwaggerUIBundle.SwaggerUIStandalonePreset\n                ],\n                layout: \"BaseLayout\",\n                tryItOutEnabled: true,\n                requestInterceptor: (request) => {\n                    request.headers['X-Mock-Scenario'] = \n                        document.getElementById('scenario-select').value;\n                    return request;\n                }\n            });\n        }\n    </script>\n    \n    <div class=\"scenario-selector\">\n        <label>Scenario:</label>\n        <select id=\"scenario-select\">\n            <option value=\"default\">Default</option>\n            <option value=\"error\">Error Conditions</option>\n            <option value=\"slow\">Slow Responses</option>\n        </select>\n    </div>\n</body>\n</html>\n'''\n```\n\n## Output Format\n\n1. **Mock Server Setup**: Complete mock server implementation\n2. **Stubbing Configuration**: Flexible request/response stubbing\n3. **Data Generation**: Realistic mock data generation\n4. **Scenario Definitions**: Comprehensive test scenarios\n5. **Contract Testing**: Contract-based mock validation\n6. **Performance Simulation**: Performance testing capabilities\n7. **Data Management**: Mock data storage and relationships\n8. **Testing Integration**: Framework integration examples\n9. **Deployment Guide**: Mock server deployment configurations\n10. **Documentation**: Auto-generated mock API documentation\n\nFocus on creating flexible, realistic mock services that enable efficient development, thorough testing, and reliable API simulation for all stages of the development lifecycle."
}