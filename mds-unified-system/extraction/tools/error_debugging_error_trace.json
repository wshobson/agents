{
  "id": "error_debugging_error_trace",
  "name": "Error Tracking and Monitoring",
  "source": "error-debugging",
  "originalPath": "plugins/error-debugging/commands/error-trace.md",
  "command": "/error-debugging:error-trace",
  "parameters": {},
  "outputs": {},
  "agentsUsing": [],
  "fullDefinition": "# Error Tracking and Monitoring\n\nYou are an error tracking and observability expert specializing in implementing comprehensive error monitoring solutions. Set up error tracking systems, configure alerts, implement structured logging, and ensure teams can quickly identify and resolve production issues.\n\n## Context\nThe user needs to implement or improve error tracking and monitoring. Focus on real-time error detection, meaningful alerts, error grouping, performance monitoring, and integration with popular error tracking services.\n\n## Requirements\n$ARGUMENTS\n\n## Instructions\n\n### 1. Error Tracking Analysis\n\nAnalyze current error handling and tracking:\n\n**Error Analysis Script**\n```python\nimport os\nimport re\nimport ast\nfrom pathlib import Path\nfrom collections import defaultdict\n\nclass ErrorTrackingAnalyzer:\n    def analyze_codebase(self, project_path):\n        \"\"\"\n        Analyze error handling patterns in codebase\n        \"\"\"\n        analysis = {\n            'error_handling': self._analyze_error_handling(project_path),\n            'logging_usage': self._analyze_logging(project_path),\n            'monitoring_setup': self._check_monitoring_setup(project_path),\n            'error_patterns': self._identify_error_patterns(project_path),\n            'recommendations': []\n        }\n        \n        self._generate_recommendations(analysis)\n        return analysis\n    \n    def _analyze_error_handling(self, project_path):\n        \"\"\"Analyze error handling patterns\"\"\"\n        patterns = {\n            'try_catch_blocks': 0,\n            'unhandled_promises': 0,\n            'generic_catches': 0,\n            'error_types': defaultdict(int),\n            'error_reporting': []\n        }\n        \n        for file_path in Path(project_path).rglob('*.{js,ts,py,java,go}'):\n            content = file_path.read_text(errors='ignore')\n            \n            # JavaScript/TypeScript patterns\n            if file_path.suffix in ['.js', '.ts']:\n                patterns['try_catch_blocks'] += len(re.findall(r'try\\s*{', content))\n                patterns['generic_catches'] += len(re.findall(r'catch\\s*\\([^)]*\\)\\s*{\\s*}', content))\n                patterns['unhandled_promises'] += len(re.findall(r'\\.then\\([^)]+\\)(?!\\.catch)', content))\n            \n            # Python patterns\n            elif file_path.suffix == '.py':\n                try:\n                    tree = ast.parse(content)\n                    for node in ast.walk(tree):\n                        if isinstance(node, ast.Try):\n                            patterns['try_catch_blocks'] += 1\n                            for handler in node.handlers:\n                                if handler.type is None:\n                                    patterns['generic_catches'] += 1\n                except:\n                    pass\n        \n        return patterns\n    \n    def _analyze_logging(self, project_path):\n        \"\"\"Analyze logging patterns\"\"\"\n        logging_patterns = {\n            'console_logs': 0,\n            'structured_logging': False,\n            'log_levels_used': set(),\n            'logging_frameworks': []\n        }\n        \n        # Check for logging frameworks\n        package_files = ['package.json', 'requirements.txt', 'go.mod', 'pom.xml']\n        for pkg_file in package_files:\n            pkg_path = Path(project_path) / pkg_file\n            if pkg_path.exists():\n                content = pkg_path.read_text()\n                if 'winston' in content or 'bunyan' in content:\n                    logging_patterns['logging_frameworks'].append('winston/bunyan')\n                if 'pino' in content:\n                    logging_patterns['logging_frameworks'].append('pino')\n                if 'logging' in content:\n                    logging_patterns['logging_frameworks'].append('python-logging')\n                if 'logrus' in content or 'zap' in content:\n                    logging_patterns['logging_frameworks'].append('logrus/zap')\n        \n        return logging_patterns\n```\n\n### 2. Error Tracking Service Integration\n\nImplement integrations with popular error tracking services:\n\n**Sentry Integration**\n```javascript\n// sentry-setup.js\nimport * as Sentry from \"@sentry/node\";\nimport { ProfilingIntegration } from \"@sentry/profiling-node\";\n\nclass SentryErrorTracker {\n    constructor(config) {\n        this.config = config;\n        this.initialized = false;\n    }\n    \n    initialize() {\n        Sentry.init({\n            dsn: this.config.dsn,\n            environment: this.config.environment,\n            release: this.config.release,\n            \n            // Performance Monitoring\n            tracesSampleRate: this.config.tracesSampleRate || 0.1,\n            profilesSampleRate: this.config.profilesSampleRate || 0.1,\n            \n            // Integrations\n            integrations: [\n                // HTTP integration\n                new Sentry.Integrations.Http({ tracing: true }),\n                \n                // Express integration\n                new Sentry.Integrations.Express({\n                    app: this.config.app,\n                    router: true,\n                    methods: ['GET', 'POST', 'PUT', 'DELETE', 'PATCH']\n                }),\n                \n                // Database integration\n                new Sentry.Integrations.Postgres(),\n                new Sentry.Integrations.Mysql(),\n                new Sentry.Integrations.Mongo(),\n                \n                // Profiling\n                new ProfilingIntegration(),\n                \n                // Custom integrations\n                ...this.getCustomIntegrations()\n            ],\n            \n            // Filtering\n            beforeSend: (event, hint) => {\n                // Filter sensitive data\n                if (event.request?.cookies) {\n                    delete event.request.cookies;\n                }\n                \n                // Filter out specific errors\n                if (this.shouldFilterError(event, hint)) {\n                    return null;\n                }\n                \n                // Enhance error context\n                return this.enhanceErrorEvent(event, hint);\n            },\n            \n            // Breadcrumbs\n            beforeBreadcrumb: (breadcrumb, hint) => {\n                // Filter sensitive breadcrumbs\n                if (breadcrumb.category === 'console' && breadcrumb.level === 'debug') {\n                    return null;\n                }\n                \n                return breadcrumb;\n            },\n            \n            // Options\n            attachStacktrace: true,\n            shutdownTimeout: 5000,\n            maxBreadcrumbs: 100,\n            debug: this.config.debug || false,\n            \n            // Tags\n            initialScope: {\n                tags: {\n                    component: this.config.component,\n                    version: this.config.version\n                },\n                user: {\n                    id: this.config.userId,\n                    segment: this.config.userSegment\n                }\n            }\n        });\n        \n        this.initialized = true;\n        this.setupErrorHandlers();\n    }\n    \n    setupErrorHandlers() {\n        // Global error handler\n        process.on('uncaughtException', (error) => {\n            console.error('Uncaught Exception:', error);\n            Sentry.captureException(error, {\n                tags: { type: 'uncaught_exception' },\n                level: 'fatal'\n            });\n            \n            // Graceful shutdown\n            this.gracefulShutdown();\n        });\n        \n        // Promise rejection handler\n        process.on('unhandledRejection', (reason, promise) => {\n            console.error('Unhandled Rejection:', reason);\n            Sentry.captureException(reason, {\n                tags: { type: 'unhandled_rejection' },\n                extra: { promise: promise.toString() }\n            });\n        });\n    }\n    \n    enhanceErrorEvent(event, hint) {\n        // Add custom context\n        event.extra = {\n            ...event.extra,\n            memory: process.memoryUsage(),\n            uptime: process.uptime(),\n            nodeVersion: process.version\n        };\n        \n        // Add user context\n        if (this.config.getUserContext) {\n            event.user = this.config.getUserContext();\n        }\n        \n        // Add custom fingerprinting\n        if (hint.originalException) {\n            event.fingerprint = this.generateFingerprint(hint.originalException);\n        }\n        \n        return event;\n    }\n    \n    generateFingerprint(error) {\n        // Custom fingerprinting logic\n        const fingerprint = [];\n        \n        // Group by error type\n        fingerprint.push(error.name || 'Error');\n        \n        // Group by error location\n        if (error.stack) {\n            const match = error.stack.match(/at\\s+(.+?)\\s+\\(/);\n            if (match) {\n                fingerprint.push(match[1]);\n            }\n        }\n        \n        // Group by custom properties\n        if (error.code) {\n            fingerprint.push(error.code);\n        }\n        \n        return fingerprint;\n    }\n}\n\n// Express middleware\nexport const sentryMiddleware = {\n    requestHandler: Sentry.Handlers.requestHandler(),\n    tracingHandler: Sentry.Handlers.tracingHandler(),\n    errorHandler: Sentry.Handlers.errorHandler({\n        shouldHandleError(error) {\n            // Capture 4xx and 5xx errors\n            if (error.status >= 400) {\n                return true;\n            }\n            return false;\n        }\n    })\n};\n```\n\n**Custom Error Tracking Service**\n```typescript\n// error-tracker.ts\ninterface ErrorEvent {\n    timestamp: Date;\n    level: 'debug' | 'info' | 'warning' | 'error' | 'fatal';\n    message: string;\n    stack?: string;\n    context: {\n        user?: any;\n        request?: any;\n        environment: string;\n        release: string;\n        tags: Record<string, string>;\n        extra: Record<string, any>;\n    };\n    fingerprint: string[];\n}\n\nclass ErrorTracker {\n    private queue: ErrorEvent[] = [];\n    private batchSize = 10;\n    private flushInterval = 5000;\n    \n    constructor(private config: ErrorTrackerConfig) {\n        this.startBatchProcessor();\n    }\n    \n    captureException(error: Error, context?: Partial<ErrorEvent['context']>) {\n        const event: ErrorEvent = {\n            timestamp: new Date(),\n            level: 'error',\n            message: error.message,\n            stack: error.stack,\n            context: {\n                environment: this.config.environment,\n                release: this.config.release,\n                tags: {},\n                extra: {},\n                ...context\n            },\n            fingerprint: this.generateFingerprint(error)\n        };\n        \n        this.addToQueue(event);\n    }\n    \n    captureMessage(message: string, level: ErrorEvent['level'] = 'info') {\n        const event: ErrorEvent = {\n            timestamp: new Date(),\n            level,\n            message,\n            context: {\n                environment: this.config.environment,\n                release: this.config.release,\n                tags: {},\n                extra: {}\n            },\n            fingerprint: [message]\n        };\n        \n        this.addToQueue(event);\n    }\n    \n    private addToQueue(event: ErrorEvent) {\n        // Apply sampling\n        if (Math.random() > this.config.sampleRate) {\n            return;\n        }\n        \n        // Filter sensitive data\n        event = this.sanitizeEvent(event);\n        \n        // Add to queue\n        this.queue.push(event);\n        \n        // Flush if queue is full\n        if (this.queue.length >= this.batchSize) {\n            this.flush();\n        }\n    }\n    \n    private sanitizeEvent(event: ErrorEvent): ErrorEvent {\n        // Remove sensitive data\n        const sensitiveKeys = ['password', 'token', 'secret', 'api_key'];\n        \n        const sanitize = (obj: any): any => {\n            if (!obj || typeof obj !== 'object') return obj;\n            \n            const cleaned = Array.isArray(obj) ? [] : {};\n            \n            for (const [key, value] of Object.entries(obj)) {\n                if (sensitiveKeys.some(k => key.toLowerCase().includes(k))) {\n                    cleaned[key] = '[REDACTED]';\n                } else if (typeof value === 'object') {\n                    cleaned[key] = sanitize(value);\n                } else {\n                    cleaned[key] = value;\n                }\n            }\n            \n            return cleaned;\n        };\n        \n        return {\n            ...event,\n            context: sanitize(event.context)\n        };\n    }\n    \n    private async flush() {\n        if (this.queue.length === 0) return;\n        \n        const events = this.queue.splice(0, this.batchSize);\n        \n        try {\n            await this.sendEvents(events);\n        } catch (error) {\n            console.error('Failed to send error events:', error);\n            // Re-queue events\n            this.queue.unshift(...events);\n        }\n    }\n    \n    private async sendEvents(events: ErrorEvent[]) {\n        const response = await fetch(this.config.endpoint, {\n            method: 'POST',\n            headers: {\n                'Content-Type': 'application/json',\n                'Authorization': `Bearer ${this.config.apiKey}`\n            },\n            body: JSON.stringify({ events })\n        });\n        \n        if (!response.ok) {\n            throw new Error(`Error tracking API returned ${response.status}`);\n        }\n    }\n}\n```\n\n### 3. Structured Logging Implementation\n\nImplement comprehensive structured logging:\n\n**Advanced Logger**\n```typescript\n// structured-logger.ts\nimport winston from 'winston';\nimport { ElasticsearchTransport } from 'winston-elasticsearch';\n\nclass StructuredLogger {\n    private logger: winston.Logger;\n    \n    constructor(config: LoggerConfig) {\n        this.logger = winston.createLogger({\n            level: config.level || 'info',\n            format: winston.format.combine(\n                winston.format.timestamp(),\n                winston.format.errors({ stack: true }),\n                winston.format.metadata(),\n                winston.format.json()\n            ),\n            defaultMeta: {\n                service: config.service,\n                environment: config.environment,\n                version: config.version\n            },\n            transports: this.createTransports(config)\n        });\n    }\n    \n    private createTransports(config: LoggerConfig): winston.transport[] {\n        const transports: winston.transport[] = [];\n        \n        // Console transport for development\n        if (config.environment === 'development') {\n            transports.push(new winston.transports.Console({\n                format: winston.format.combine(\n                    winston.format.colorize(),\n                    winston.format.simple()\n                )\n            }));\n        }\n        \n        // File transport for all environments\n        transports.push(new winston.transports.File({\n            filename: 'logs/error.log',\n            level: 'error',\n            maxsize: 5242880, // 5MB\n            maxFiles: 5\n        }));\n        \n        transports.push(new winston.transports.File({\n            filename: 'logs/combined.log',\n            maxsize: 5242880,\n            maxFiles: 5\n        });\n        \n        // Elasticsearch transport for production\n        if (config.elasticsearch) {\n            transports.push(new ElasticsearchTransport({\n                level: 'info',\n                clientOpts: config.elasticsearch,\n                index: `logs-${config.service}`,\n                transformer: (logData) => {\n                    return {\n                        '@timestamp': logData.timestamp,\n                        severity: logData.level,\n                        message: logData.message,\n                        fields: {\n                            ...logData.metadata,\n                            ...logData.defaultMeta\n                        }\n                    };\n                }\n            }));\n        }\n        \n        return transports;\n    }\n    \n    // Logging methods with context\n    error(message: string, error?: Error, context?: any) {\n        this.logger.error(message, {\n            error: {\n                message: error?.message,\n                stack: error?.stack,\n                name: error?.name\n            },\n            ...context\n        });\n    }\n    \n    warn(message: string, context?: any) {\n        this.logger.warn(message, context);\n    }\n    \n    info(message: string, context?: any) {\n        this.logger.info(message, context);\n    }\n    \n    debug(message: string, context?: any) {\n        this.logger.debug(message, context);\n    }\n    \n    // Performance logging\n    startTimer(label: string): () => void {\n        const start = Date.now();\n        return () => {\n            const duration = Date.now() - start;\n            this.info(`Timer ${label}`, { duration, label });\n        };\n    }\n    \n    // Audit logging\n    audit(action: string, userId: string, details: any) {\n        this.info('Audit Event', {\n            type: 'audit',\n            action,\n            userId,\n            timestamp: new Date().toISOString(),\n            details\n        });\n    }\n}\n\n// Request logging middleware\nexport function requestLoggingMiddleware(logger: StructuredLogger) {\n    return (req: Request, res: Response, next: NextFunction) => {\n        const start = Date.now();\n        \n        // Log request\n        logger.info('Incoming request', {\n            method: req.method,\n            url: req.url,\n            ip: req.ip,\n            userAgent: req.get('user-agent')\n        });\n        \n        // Log response\n        res.on('finish', () => {\n            const duration = Date.now() - start;\n            logger.info('Request completed', {\n                method: req.method,\n                url: req.url,\n                status: res.statusCode,\n                duration,\n                contentLength: res.get('content-length')\n            });\n        });\n        \n        next();\n    };\n}\n```\n\n### 4. Error Alerting Configuration\n\nSet up intelligent alerting:\n\n**Alert Manager**\n```python\n# alert_manager.py\nfrom dataclasses import dataclass\nfrom typing import List, Dict, Optional\nfrom datetime import datetime, timedelta\nimport asyncio\n\n@dataclass\nclass AlertRule:\n    name: str\n    condition: str\n    threshold: float\n    window: timedelta\n    severity: str\n    channels: List[str]\n    cooldown: timedelta = timedelta(minutes=15)\n\nclass AlertManager:\n    def __init__(self, config):\n        self.config = config\n        self.rules = self._load_rules()\n        self.alert_history = {}\n        self.channels = self._setup_channels()\n    \n    def _load_rules(self):\n        \"\"\"Load alert rules from configuration\"\"\"\n        return [\n            AlertRule(\n                name=\"High Error Rate\",\n                condition=\"error_rate\",\n                threshold=0.05,  # 5% error rate\n                window=timedelta(minutes=5),\n                severity=\"critical\",\n                channels=[\"slack\", \"pagerduty\"]\n            ),\n            AlertRule(\n                name=\"Response Time Degradation\",\n                condition=\"response_time_p95\",\n                threshold=1000,  # 1 second\n                window=timedelta(minutes=10),\n                severity=\"warning\",\n                channels=[\"slack\"]\n            ),\n            AlertRule(\n                name=\"Memory Usage Critical\",\n                condition=\"memory_usage_percent\",\n                threshold=90,\n                window=timedelta(minutes=5),\n                severity=\"critical\",\n                channels=[\"slack\", \"pagerduty\"]\n            ),\n            AlertRule(\n                name=\"Disk Space Low\",\n                condition=\"disk_free_percent\",\n                threshold=10,\n                window=timedelta(minutes=15),\n                severity=\"warning\",\n                channels=[\"slack\", \"email\"]\n            )\n        ]\n    \n    async def evaluate_rules(self, metrics: Dict):\n        \"\"\"Evaluate all alert rules against current metrics\"\"\"\n        for rule in self.rules:\n            if await self._should_alert(rule, metrics):\n                await self._send_alert(rule, metrics)\n    \n    async def _should_alert(self, rule: AlertRule, metrics: Dict) -> bool:\n        \"\"\"Check if alert should be triggered\"\"\"\n        # Check if metric exists\n        if rule.condition not in metrics:\n            return False\n        \n        # Check threshold\n        value = metrics[rule.condition]\n        if not self._check_threshold(value, rule.threshold, rule.condition):\n            return False\n        \n        # Check cooldown\n        last_alert = self.alert_history.get(rule.name)\n        if last_alert and datetime.now() - last_alert < rule.cooldown:\n            return False\n        \n        return True\n    \n    async def _send_alert(self, rule: AlertRule, metrics: Dict):\n        \"\"\"Send alert through configured channels\"\"\"\n        alert_data = {\n            \"rule\": rule.name,\n            \"severity\": rule.severity,\n            \"value\": metrics[rule.condition],\n            \"threshold\": rule.threshold,\n            \"timestamp\": datetime.now().isoformat(),\n            \"environment\": self.config.environment,\n            \"service\": self.config.service\n        }\n        \n        # Send to all channels\n        tasks = []\n        for channel_name in rule.channels:\n            if channel_name in self.channels:\n                channel = self.channels[channel_name]\n                tasks.append(channel.send(alert_data))\n        \n        await asyncio.gather(*tasks)\n        \n        # Update alert history\n        self.alert_history[rule.name] = datetime.now()\n\n# Alert channels\nclass SlackAlertChannel:\n    def __init__(self, webhook_url):\n        self.webhook_url = webhook_url\n    \n    async def send(self, alert_data):\n        \"\"\"Send alert to Slack\"\"\"\n        color = {\n            \"critical\": \"danger\",\n            \"warning\": \"warning\",\n            \"info\": \"good\"\n        }.get(alert_data[\"severity\"], \"danger\")\n        \n        payload = {\n            \"attachments\": [{\n                \"color\": color,\n                \"title\": f\"\ud83d\udea8 {alert_data['rule']}\",\n                \"fields\": [\n                    {\n                        \"title\": \"Severity\",\n                        \"value\": alert_data[\"severity\"].upper(),\n                        \"short\": True\n                    },\n                    {\n                        \"title\": \"Environment\",\n                        \"value\": alert_data[\"environment\"],\n                        \"short\": True\n                    },\n                    {\n                        \"title\": \"Current Value\",\n                        \"value\": str(alert_data[\"value\"]),\n                        \"short\": True\n                    },\n                    {\n                        \"title\": \"Threshold\",\n                        \"value\": str(alert_data[\"threshold\"]),\n                        \"short\": True\n                    }\n                ],\n                \"footer\": alert_data[\"service\"],\n                \"ts\": int(datetime.now().timestamp())\n            }]\n        }\n        \n        # Send to Slack\n        async with aiohttp.ClientSession() as session:\n            await session.post(self.webhook_url, json=payload)\n```\n\n### 5. Error Grouping and Deduplication\n\nImplement intelligent error grouping:\n\n**Error Grouping Algorithm**\n```python\nimport hashlib\nimport re\nfrom difflib import SequenceMatcher\n\nclass ErrorGrouper:\n    def __init__(self):\n        self.groups = {}\n        self.patterns = self._compile_patterns()\n    \n    def _compile_patterns(self):\n        \"\"\"Compile regex patterns for normalization\"\"\"\n        return {\n            'numbers': re.compile(r'\\b\\d+\\b'),\n            'uuids': re.compile(r'[a-f0-9]{8}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{12}'),\n            'urls': re.compile(r'https?://[^\\s]+'),\n            'file_paths': re.compile(r'(/[^/\\s]+)+'),\n            'memory_addresses': re.compile(r'0x[0-9a-fA-F]+'),\n            'timestamps': re.compile(r'\\d{4}-\\d{2}-\\d{2}[T\\s]\\d{2}:\\d{2}:\\d{2}')\n        }\n    \n    def group_error(self, error):\n        \"\"\"Group error with similar errors\"\"\"\n        fingerprint = self.generate_fingerprint(error)\n        \n        # Find existing group\n        group = self.find_similar_group(fingerprint, error)\n        \n        if group:\n            group['count'] += 1\n            group['last_seen'] = error['timestamp']\n            group['instances'].append(error)\n        else:\n            # Create new group\n            self.groups[fingerprint] = {\n                'fingerprint': fingerprint,\n                'first_seen': error['timestamp'],\n                'last_seen': error['timestamp'],\n                'count': 1,\n                'instances': [error],\n                'pattern': self.extract_pattern(error)\n            }\n        \n        return fingerprint\n    \n    def generate_fingerprint(self, error):\n        \"\"\"Generate unique fingerprint for error\"\"\"\n        # Normalize error message\n        normalized = self.normalize_message(error['message'])\n        \n        # Include error type and location\n        components = [\n            error.get('type', 'Unknown'),\n            normalized,\n            self.extract_location(error.get('stack', ''))\n        ]\n        \n        # Generate hash\n        fingerprint = hashlib.sha256(\n            '|'.join(components).encode()\n        ).hexdigest()[:16]\n        \n        return fingerprint\n    \n    def normalize_message(self, message):\n        \"\"\"Normalize error message for grouping\"\"\"\n        # Replace dynamic values\n        normalized = message\n        for pattern_name, pattern in self.patterns.items():\n            normalized = pattern.sub(f'<{pattern_name}>', normalized)\n        \n        return normalized.strip()\n    \n    def extract_location(self, stack):\n        \"\"\"Extract error location from stack trace\"\"\"\n        if not stack:\n            return 'unknown'\n        \n        lines = stack.split('\\n')\n        for line in lines:\n            # Look for file references\n            if ' at ' in line:\n                # Extract file and line number\n                match = re.search(r'at\\s+(.+?)\\s*\\((.+?):(\\d+):(\\d+)\\)', line)\n                if match:\n                    file_path = match.group(2)\n                    # Normalize file path\n                    file_path = re.sub(r'.*/(?=src/|lib/|app/)', '', file_path)\n                    return f\"{file_path}:{match.group(3)}\"\n        \n        return 'unknown'\n    \n    def find_similar_group(self, fingerprint, error):\n        \"\"\"Find similar error group using fuzzy matching\"\"\"\n        if fingerprint in self.groups:\n            return self.groups[fingerprint]\n        \n        # Try fuzzy matching\n        normalized_message = self.normalize_message(error['message'])\n        \n        for group_fp, group in self.groups.items():\n            similarity = SequenceMatcher(\n                None,\n                normalized_message,\n                group['pattern']\n            ).ratio()\n            \n            if similarity > 0.85:  # 85% similarity threshold\n                return group\n        \n        return None\n```\n\n### 6. Performance Impact Tracking\n\nMonitor performance impact of errors:\n\n**Performance Monitor**\n```typescript\n// performance-monitor.ts\ninterface PerformanceMetrics {\n    responseTime: number;\n    errorRate: number;\n    throughput: number;\n    apdex: number;\n    resourceUsage: {\n        cpu: number;\n        memory: number;\n        disk: number;\n    };\n}\n\nclass PerformanceMonitor {\n    private metrics: Map<string, PerformanceMetrics[]> = new Map();\n    private intervals: Map<string, NodeJS.Timer> = new Map();\n    \n    startMonitoring(service: string, interval: number = 60000) {\n        const timer = setInterval(() => {\n            this.collectMetrics(service);\n        }, interval);\n        \n        this.intervals.set(service, timer);\n    }\n    \n    private async collectMetrics(service: string) {\n        const metrics: PerformanceMetrics = {\n            responseTime: await this.getResponseTime(service),\n            errorRate: await this.getErrorRate(service),\n            throughput: await this.getThroughput(service),\n            apdex: await this.calculateApdex(service),\n            resourceUsage: await this.getResourceUsage()\n        };\n        \n        // Store metrics\n        if (!this.metrics.has(service)) {\n            this.metrics.set(service, []);\n        }\n        \n        const serviceMetrics = this.metrics.get(service)!;\n        serviceMetrics.push(metrics);\n        \n        // Keep only last 24 hours\n        const dayAgo = Date.now() - 24 * 60 * 60 * 1000;\n        const filtered = serviceMetrics.filter(m => m.timestamp > dayAgo);\n        this.metrics.set(service, filtered);\n        \n        // Check for anomalies\n        this.detectAnomalies(service, metrics);\n    }\n    \n    private detectAnomalies(service: string, current: PerformanceMetrics) {\n        const history = this.metrics.get(service) || [];\n        if (history.length < 10) return; // Need history for comparison\n        \n        // Calculate baselines\n        const baseline = this.calculateBaseline(history.slice(-60)); // Last hour\n        \n        // Check for anomalies\n        const anomalies = [];\n        \n        if (current.responseTime > baseline.responseTime * 2) {\n            anomalies.push({\n                type: 'response_time_spike',\n                severity: 'warning',\n                value: current.responseTime,\n                baseline: baseline.responseTime\n            });\n        }\n        \n        if (current.errorRate > baseline.errorRate + 0.05) {\n            anomalies.push({\n                type: 'error_rate_increase',\n                severity: 'critical',\n                value: current.errorRate,\n                baseline: baseline.errorRate\n            });\n        }\n        \n        if (anomalies.length > 0) {\n            this.reportAnomalies(service, anomalies);\n        }\n    }\n    \n    private calculateBaseline(history: PerformanceMetrics[]) {\n        const sum = history.reduce((acc, m) => ({\n            responseTime: acc.responseTime + m.responseTime,\n            errorRate: acc.errorRate + m.errorRate,\n            throughput: acc.throughput + m.throughput,\n            apdex: acc.apdex + m.apdex\n        }), {\n            responseTime: 0,\n            errorRate: 0,\n            throughput: 0,\n            apdex: 0\n        });\n        \n        return {\n            responseTime: sum.responseTime / history.length,\n            errorRate: sum.errorRate / history.length,\n            throughput: sum.throughput / history.length,\n            apdex: sum.apdex / history.length\n        };\n    }\n    \n    async calculateApdex(service: string, threshold: number = 500) {\n        // Apdex = (Satisfied + Tolerating/2) / Total\n        const satisfied = await this.countRequests(service, 0, threshold);\n        const tolerating = await this.countRequests(service, threshold, threshold * 4);\n        const total = await this.getTotalRequests(service);\n        \n        if (total === 0) return 1;\n        \n        return (satisfied + tolerating / 2) / total;\n    }\n}\n```\n\n### 7. Error Recovery Strategies\n\nImplement automatic error recovery:\n\n**Recovery Manager**\n```javascript\n// recovery-manager.js\nclass RecoveryManager {\n    constructor(config) {\n        this.strategies = new Map();\n        this.retryPolicies = config.retryPolicies || {};\n        this.circuitBreakers = new Map();\n        this.registerDefaultStrategies();\n    }\n    \n    registerStrategy(errorType, strategy) {\n        this.strategies.set(errorType, strategy);\n    }\n    \n    registerDefaultStrategies() {\n        // Network errors\n        this.registerStrategy('NetworkError', async (error, context) => {\n            return this.retryWithBackoff(\n                context.operation,\n                this.retryPolicies.network || {\n                    maxRetries: 3,\n                    baseDelay: 1000,\n                    maxDelay: 10000\n                }\n            );\n        });\n        \n        // Database errors\n        this.registerStrategy('DatabaseError', async (error, context) => {\n            // Try read replica if available\n            if (context.operation.type === 'read' && context.readReplicas) {\n                return this.tryReadReplica(context);\n            }\n            \n            // Otherwise retry with backoff\n            return this.retryWithBackoff(\n                context.operation,\n                this.retryPolicies.database || {\n                    maxRetries: 2,\n                    baseDelay: 500,\n                    maxDelay: 5000\n                }\n            );\n        });\n        \n        // Rate limit errors\n        this.registerStrategy('RateLimitError', async (error, context) => {\n            const retryAfter = error.retryAfter || 60;\n            await this.delay(retryAfter * 1000);\n            return context.operation();\n        });\n        \n        // Circuit breaker for external services\n        this.registerStrategy('ExternalServiceError', async (error, context) => {\n            const breaker = this.getCircuitBreaker(context.service);\n            \n            try {\n                return await breaker.execute(context.operation);\n            } catch (error) {\n                // Fallback to cache or default\n                if (context.fallback) {\n                    return context.fallback();\n                }\n                throw error;\n            }\n        });\n    }\n    \n    async recover(error, context) {\n        const errorType = this.classifyError(error);\n        const strategy = this.strategies.get(errorType);\n        \n        if (!strategy) {\n            // No recovery strategy, rethrow\n            throw error;\n        }\n        \n        try {\n            const result = await strategy(error, context);\n            \n            // Log recovery success\n            this.logRecovery(error, errorType, 'success');\n            \n            return result;\n        } catch (recoveryError) {\n            // Log recovery failure\n            this.logRecovery(error, errorType, 'failure', recoveryError);\n            \n            // Throw original error\n            throw error;\n        }\n    }\n    \n    async retryWithBackoff(operation, policy) {\n        let lastError;\n        let delay = policy.baseDelay;\n        \n        for (let attempt = 0; attempt < policy.maxRetries; attempt++) {\n            try {\n                return await operation();\n            } catch (error) {\n                lastError = error;\n                \n                if (attempt < policy.maxRetries - 1) {\n                    await this.delay(delay);\n                    delay = Math.min(delay * 2, policy.maxDelay);\n                }\n            }\n        }\n        \n        throw lastError;\n    }\n    \n    getCircuitBreaker(service) {\n        if (!this.circuitBreakers.has(service)) {\n            this.circuitBreakers.set(service, new CircuitBreaker({\n                timeout: 3000,\n                errorThresholdPercentage: 50,\n                resetTimeout: 30000,\n                rollingCountTimeout: 10000,\n                rollingCountBuckets: 10,\n                volumeThreshold: 10\n            }));\n        }\n        \n        return this.circuitBreakers.get(service);\n    }\n    \n    classifyError(error) {\n        // Classify by error code\n        if (error.code === 'ECONNREFUSED' || error.code === 'ETIMEDOUT') {\n            return 'NetworkError';\n        }\n        \n        if (error.code === 'ER_LOCK_DEADLOCK' || error.code === 'SQLITE_BUSY') {\n            return 'DatabaseError';\n        }\n        \n        if (error.status === 429) {\n            return 'RateLimitError';\n        }\n        \n        if (error.isExternalService) {\n            return 'ExternalServiceError';\n        }\n        \n        // Default\n        return 'UnknownError';\n    }\n}\n\n// Circuit breaker implementation\nclass CircuitBreaker {\n    constructor(options) {\n        this.options = options;\n        this.state = 'CLOSED';\n        this.failures = 0;\n        this.successes = 0;\n        this.nextAttempt = Date.now();\n    }\n    \n    async execute(operation) {\n        if (this.state === 'OPEN') {\n            if (Date.now() < this.nextAttempt) {\n                throw new Error('Circuit breaker is OPEN');\n            }\n            \n            // Try half-open\n            this.state = 'HALF_OPEN';\n        }\n        \n        try {\n            const result = await Promise.race([\n                operation(),\n                this.timeout(this.options.timeout)\n            ]);\n            \n            this.onSuccess();\n            return result;\n        } catch (error) {\n            this.onFailure();\n            throw error;\n        }\n    }\n    \n    onSuccess() {\n        this.failures = 0;\n        \n        if (this.state === 'HALF_OPEN') {\n            this.successes++;\n            if (this.successes >= this.options.volumeThreshold) {\n                this.state = 'CLOSED';\n                this.successes = 0;\n            }\n        }\n    }\n    \n    onFailure() {\n        this.failures++;\n        \n        if (this.state === 'HALF_OPEN') {\n            this.state = 'OPEN';\n            this.nextAttempt = Date.now() + this.options.resetTimeout;\n        } else if (this.failures >= this.options.volumeThreshold) {\n            this.state = 'OPEN';\n            this.nextAttempt = Date.now() + this.options.resetTimeout;\n        }\n    }\n}\n```\n\n### 8. Error Dashboard\n\nCreate comprehensive error dashboard:\n\n**Dashboard Component**\n```typescript\n// error-dashboard.tsx\nimport React from 'react';\nimport { LineChart, BarChart, PieChart } from 'recharts';\n\nconst ErrorDashboard: React.FC = () => {\n    const [metrics, setMetrics] = useState<DashboardMetrics>();\n    const [timeRange, setTimeRange] = useState('1h');\n    \n    useEffect(() => {\n        const fetchMetrics = async () => {\n            const data = await getErrorMetrics(timeRange);\n            setMetrics(data);\n        };\n        \n        fetchMetrics();\n        const interval = setInterval(fetchMetrics, 30000); // Update every 30s\n        \n        return () => clearInterval(interval);\n    }, [timeRange]);\n    \n    if (!metrics) return <Loading />;\n    \n    return (\n        <div className=\"error-dashboard\">\n            <Header>\n                <h1>Error Tracking Dashboard</h1>\n                <TimeRangeSelector\n                    value={timeRange}\n                    onChange={setTimeRange}\n                    options={['1h', '6h', '24h', '7d', '30d']}\n                />\n            </Header>\n            \n            <MetricCards>\n                <MetricCard\n                    title=\"Error Rate\"\n                    value={`${(metrics.errorRate * 100).toFixed(2)}%`}\n                    trend={metrics.errorRateTrend}\n                    status={metrics.errorRate > 0.05 ? 'critical' : 'ok'}\n                />\n                <MetricCard\n                    title=\"Total Errors\"\n                    value={metrics.totalErrors.toLocaleString()}\n                    trend={metrics.errorsTrend}\n                />\n                <MetricCard\n                    title=\"Affected Users\"\n                    value={metrics.affectedUsers.toLocaleString()}\n                    trend={metrics.usersTrend}\n                />\n                <MetricCard\n                    title=\"MTTR\"\n                    value={formatDuration(metrics.mttr)}\n                    trend={metrics.mttrTrend}\n                />\n            </MetricCards>\n            \n            <ChartGrid>\n                <ChartCard title=\"Error Trend\">\n                    <LineChart data={metrics.errorTrend}>\n                        <Line\n                            type=\"monotone\"\n                            dataKey=\"errors\"\n                            stroke=\"#ff6b6b\"\n                            strokeWidth={2}\n                        />\n                        <Line\n                            type=\"monotone\"\n                            dataKey=\"warnings\"\n                            stroke=\"#ffd93d\"\n                            strokeWidth={2}\n                        />\n                    </LineChart>\n                </ChartCard>\n                \n                <ChartCard title=\"Error Distribution\">\n                    <PieChart data={metrics.errorDistribution}>\n                        <Pie\n                            dataKey=\"count\"\n                            nameKey=\"type\"\n                            cx=\"50%\"\n                            cy=\"50%\"\n                            outerRadius={80}\n                        />\n                    </PieChart>\n                </ChartCard>\n                \n                <ChartCard title=\"Top Errors\">\n                    <BarChart data={metrics.topErrors}>\n                        <Bar dataKey=\"count\" fill=\"#ff6b6b\" />\n                    </BarChart>\n                </ChartCard>\n                \n                <ChartCard title=\"Error Heatmap\">\n                    <ErrorHeatmap data={metrics.errorHeatmap} />\n                </ChartCard>\n            </ChartGrid>\n            \n            <ErrorList>\n                <h2>Recent Errors</h2>\n                <ErrorTable\n                    errors={metrics.recentErrors}\n                    onErrorClick={handleErrorClick}\n                />\n            </ErrorList>\n            \n            <AlertsSection>\n                <h2>Active Alerts</h2>\n                <AlertsList alerts={metrics.activeAlerts} />\n            </AlertsSection>\n        </div>\n    );\n};\n\n// Real-time error stream\nconst ErrorStream: React.FC = () => {\n    const [errors, setErrors] = useState<ErrorEvent[]>([]);\n    \n    useEffect(() => {\n        const eventSource = new EventSource('/api/errors/stream');\n        \n        eventSource.onmessage = (event) => {\n            const error = JSON.parse(event.data);\n            setErrors(prev => [error, ...prev].slice(0, 100));\n        };\n        \n        return () => eventSource.close();\n    }, []);\n    \n    return (\n        <div className=\"error-stream\">\n            <h3>Live Error Stream</h3>\n            <div className=\"stream-container\">\n                {errors.map((error, index) => (\n                    <ErrorStreamItem\n                        key={error.id}\n                        error={error}\n                        isNew={index === 0}\n                    />\n                ))}\n            </div>\n        </div>\n    );\n};\n```\n\n## Output Format\n\n1. **Error Tracking Analysis**: Current error handling assessment\n2. **Integration Configuration**: Setup for error tracking services\n3. **Logging Implementation**: Structured logging setup\n4. **Alert Rules**: Intelligent alerting configuration\n5. **Error Grouping**: Deduplication and grouping logic\n6. **Recovery Strategies**: Automatic error recovery implementation\n7. **Dashboard Setup**: Real-time error monitoring dashboard\n8. **Documentation**: Implementation and troubleshooting guide\n\nFocus on providing comprehensive error visibility, intelligent alerting, and quick error resolution capabilities."
}