{
  "id": "application_performance_performance_optimization",
  "name": "performance-optimization",
  "source": "application-performance",
  "originalPath": "plugins/application-performance/commands/performance-optimization.md",
  "command": "/application-performance:performance-optimization",
  "parameters": {},
  "outputs": {},
  "agentsUsing": [],
  "fullDefinition": "Optimize application performance end-to-end using specialized performance and optimization agents:\n\n[Extended thinking: This workflow orchestrates a comprehensive performance optimization process across the entire application stack. Starting with deep profiling and baseline establishment, the workflow progresses through targeted optimizations in each system layer, validates improvements through load testing, and establishes continuous monitoring for sustained performance. Each phase builds on insights from previous phases, creating a data-driven optimization strategy that addresses real bottlenecks rather than theoretical improvements. The workflow emphasizes modern observability practices, user-centric performance metrics, and cost-effective optimization strategies.]\n\n## Phase 1: Performance Profiling & Baseline\n\n### 1. Comprehensive Performance Profiling\n- Use Task tool with subagent_type=\"performance-engineer\"\n- Prompt: \"Profile application performance comprehensively for: $ARGUMENTS. Generate flame graphs for CPU usage, heap dumps for memory analysis, trace I/O operations, and identify hot paths. Use APM tools like DataDog or New Relic if available. Include database query profiling, API response times, and frontend rendering metrics. Establish performance baselines for all critical user journeys.\"\n- Context: Initial performance investigation\n- Output: Detailed performance profile with flame graphs, memory analysis, bottleneck identification, baseline metrics\n\n### 2. Observability Stack Assessment\n- Use Task tool with subagent_type=\"observability-engineer\"\n- Prompt: \"Assess current observability setup for: $ARGUMENTS. Review existing monitoring, distributed tracing with OpenTelemetry, log aggregation, and metrics collection. Identify gaps in visibility, missing metrics, and areas needing better instrumentation. Recommend APM tool integration and custom metrics for business-critical operations.\"\n- Context: Performance profile from step 1\n- Output: Observability assessment report, instrumentation gaps, monitoring recommendations\n\n### 3. User Experience Analysis\n- Use Task tool with subagent_type=\"performance-engineer\"\n- Prompt: \"Analyze user experience metrics for: $ARGUMENTS. Measure Core Web Vitals (LCP, FID, CLS), page load times, time to interactive, and perceived performance. Use Real User Monitoring (RUM) data if available. Identify user journeys with poor performance and their business impact.\"\n- Context: Performance baselines from step 1\n- Output: UX performance report, Core Web Vitals analysis, user impact assessment\n\n## Phase 2: Database & Backend Optimization\n\n### 4. Database Performance Optimization\n- Use Task tool with subagent_type=\"database-cloud-optimization::database-optimizer\"\n- Prompt: \"Optimize database performance for: $ARGUMENTS based on profiling data: {context_from_phase_1}. Analyze slow query logs, create missing indexes, optimize execution plans, implement query result caching with Redis/Memcached. Review connection pooling, prepared statements, and batch processing opportunities. Consider read replicas and database sharding if needed.\"\n- Context: Performance bottlenecks from phase 1\n- Output: Optimized queries, new indexes, caching strategy, connection pool configuration\n\n### 5. Backend Code & API Optimization\n- Use Task tool with subagent_type=\"backend-development::backend-architect\"\n- Prompt: \"Optimize backend services for: $ARGUMENTS targeting bottlenecks: {context_from_phase_1}. Implement efficient algorithms, add application-level caching, optimize N+1 queries, use async/await patterns effectively. Implement pagination, response compression, GraphQL query optimization, and batch API operations. Add circuit breakers and bulkheads for resilience.\"\n- Context: Database optimizations from step 4, profiling data from phase 1\n- Output: Optimized backend code, caching implementation, API improvements, resilience patterns\n\n### 6. Microservices & Distributed System Optimization\n- Use Task tool with subagent_type=\"performance-engineer\"\n- Prompt: \"Optimize distributed system performance for: $ARGUMENTS. Analyze service-to-service communication, implement service mesh optimizations, optimize message queue performance (Kafka/RabbitMQ), reduce network hops. Implement distributed caching strategies and optimize serialization/deserialization.\"\n- Context: Backend optimizations from step 5\n- Output: Service communication improvements, message queue optimization, distributed caching setup\n\n## Phase 3: Frontend & CDN Optimization\n\n### 7. Frontend Bundle & Loading Optimization\n- Use Task tool with subagent_type=\"frontend-developer\"\n- Prompt: \"Optimize frontend performance for: $ARGUMENTS targeting Core Web Vitals: {context_from_phase_1}. Implement code splitting, tree shaking, lazy loading, and dynamic imports. Optimize bundle sizes with webpack/rollup analysis. Implement resource hints (prefetch, preconnect, preload). Optimize critical rendering path and eliminate render-blocking resources.\"\n- Context: UX analysis from phase 1, backend optimizations from phase 2\n- Output: Optimized bundles, lazy loading implementation, improved Core Web Vitals\n\n### 8. CDN & Edge Optimization\n- Use Task tool with subagent_type=\"cloud-infrastructure::cloud-architect\"\n- Prompt: \"Optimize CDN and edge performance for: $ARGUMENTS. Configure CloudFlare/CloudFront for optimal caching, implement edge functions for dynamic content, set up image optimization with responsive images and WebP/AVIF formats. Configure HTTP/2 and HTTP/3, implement Brotli compression. Set up geographic distribution for global users.\"\n- Context: Frontend optimizations from step 7\n- Output: CDN configuration, edge caching rules, compression setup, geographic optimization\n\n### 9. Mobile & Progressive Web App Optimization\n- Use Task tool with subagent_type=\"frontend-mobile-development::mobile-developer\"\n- Prompt: \"Optimize mobile experience for: $ARGUMENTS. Implement service workers for offline functionality, optimize for slow networks with adaptive loading. Reduce JavaScript execution time for mobile CPUs. Implement virtual scrolling for long lists. Optimize touch responsiveness and smooth animations. Consider React Native/Flutter specific optimizations if applicable.\"\n- Context: Frontend optimizations from steps 7-8\n- Output: Mobile-optimized code, PWA implementation, offline functionality\n\n## Phase 4: Load Testing & Validation\n\n### 10. Comprehensive Load Testing\n- Use Task tool with subagent_type=\"performance-engineer\"\n- Prompt: \"Conduct comprehensive load testing for: $ARGUMENTS using k6/Gatling/Artillery. Design realistic load scenarios based on production traffic patterns. Test normal load, peak load, and stress scenarios. Include API testing, browser-based testing, and WebSocket testing if applicable. Measure response times, throughput, error rates, and resource utilization at various load levels.\"\n- Context: All optimizations from phases 1-3\n- Output: Load test results, performance under load, breaking points, scalability analysis\n\n### 11. Performance Regression Testing\n- Use Task tool with subagent_type=\"performance-testing-review::test-automator\"\n- Prompt: \"Create automated performance regression tests for: $ARGUMENTS. Set up performance budgets for key metrics, integrate with CI/CD pipeline using GitHub Actions or similar. Create Lighthouse CI tests for frontend, API performance tests with Artillery, and database performance benchmarks. Implement automatic rollback triggers for performance regressions.\"\n- Context: Load test results from step 10, baseline metrics from phase 1\n- Output: Performance test suite, CI/CD integration, regression prevention system\n\n## Phase 5: Monitoring & Continuous Optimization\n\n### 12. Production Monitoring Setup\n- Use Task tool with subagent_type=\"observability-engineer\"\n- Prompt: \"Implement production performance monitoring for: $ARGUMENTS. Set up APM with DataDog/New Relic/Dynatrace, configure distributed tracing with OpenTelemetry, implement custom business metrics. Create Grafana dashboards for key metrics, set up PagerDuty alerts for performance degradation. Define SLIs/SLOs for critical services with error budgets.\"\n- Context: Performance improvements from all previous phases\n- Output: Monitoring dashboards, alert rules, SLI/SLO definitions, runbooks\n\n### 13. Continuous Performance Optimization\n- Use Task tool with subagent_type=\"performance-engineer\"\n- Prompt: \"Establish continuous optimization process for: $ARGUMENTS. Create performance budget tracking, implement A/B testing for performance changes, set up continuous profiling in production. Document optimization opportunities backlog, create capacity planning models, and establish regular performance review cycles.\"\n- Context: Monitoring setup from step 12, all previous optimization work\n- Output: Performance budget tracking, optimization backlog, capacity planning, review process\n\n## Configuration Options\n\n- **performance_focus**: \"latency\" | \"throughput\" | \"cost\" | \"balanced\" (default: \"balanced\")\n- **optimization_depth**: \"quick-wins\" | \"comprehensive\" | \"enterprise\" (default: \"comprehensive\")\n- **tools_available**: [\"datadog\", \"newrelic\", \"prometheus\", \"grafana\", \"k6\", \"gatling\"]\n- **budget_constraints**: Set maximum acceptable costs for infrastructure changes\n- **user_impact_tolerance**: \"zero-downtime\" | \"maintenance-window\" | \"gradual-rollout\"\n\n## Success Criteria\n\n- **Response Time**: P50 < 200ms, P95 < 1s, P99 < 2s for critical endpoints\n- **Core Web Vitals**: LCP < 2.5s, FID < 100ms, CLS < 0.1\n- **Throughput**: Support 2x current peak load with <1% error rate\n- **Database Performance**: Query P95 < 100ms, no queries > 1s\n- **Resource Utilization**: CPU < 70%, Memory < 80% under normal load\n- **Cost Efficiency**: Performance per dollar improved by minimum 30%\n- **Monitoring Coverage**: 100% of critical paths instrumented with alerting\n\nPerformance optimization target: $ARGUMENTS"
}